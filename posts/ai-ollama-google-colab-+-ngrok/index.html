<!doctype html><html lang=zh-tw><head><link rel=preload href=/lib/font-awesome/webfonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/font-awesome/webfonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/font-awesome/webfonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><script type=text/javascript src=https://latest.cactus.chat/cactus.js></script>
<link rel=stylesheet href=https://latest.cactus.chat/style.css type=text/css><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>AI - Ollama - Google Colab + ngrok | 識之箱庭</title><link rel=canonical href=https://HoshikawaRyuukou.github.io/posts/ai-ollama-google-colab-+-ngrok/><meta name=description content="紙上得來終覺淺，絕知此事要躬行。"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="AI - Ollama - Google Colab + ngrok"><meta property="og:description" content="Quick Chat 參考以下教學
十分钟部署本地离线免费大模型！ Ngrok + Ollama | 在世界任何地方与localhost开源大模型聊天 Free Inference Is All I Need: How to Run Large Language Models for Free Using Google Colab Requirements 註冊 ngrok 帳號，取得 token ( ngrok > Your Authtoken ) 將 token 填至 colab > Secret name : NGROK_AUTH value : token 本機端使用 Page Assist - A Web UI for Local AI Models 與 Ollama 互動 Steps 安裝必要工具 !sudo apt-get install -y pciutils !"><meta property="og:type" content="article"><meta property="og:url" content="https://HoshikawaRyuukou.github.io/posts/ai-ollama-google-colab-+-ngrok/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-16T21:11:00+00:00"><meta property="article:modified_time" content="2025-01-16T21:11:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI - Ollama - Google Colab + ngrok"><meta name=twitter:description content="Quick Chat 參考以下教學
十分钟部署本地离线免费大模型！ Ngrok + Ollama | 在世界任何地方与localhost开源大模型聊天 Free Inference Is All I Need: How to Run Large Language Models for Free Using Google Colab Requirements 註冊 ngrok 帳號，取得 token ( ngrok > Your Authtoken ) 將 token 填至 colab > Secret name : NGROK_AUTH value : token 本機端使用 Page Assist - A Web UI for Local AI Models 與 Ollama 互動 Steps 安裝必要工具 !sudo apt-get install -y pciutils !"><link rel=stylesheet href=https://HoshikawaRyuukou.github.io/css/styles.9293a5aa5b416dbdce7874b0376fe51f0f87bf229c7ce1755fbd1781f23fa9827cd260fa3ddcf564888c14d68ee88809d3425b7342484bf1cb82d6d8371e51f5.css integrity="sha512-kpOlqltBbb3OeHSwN2/lHw+HvyKcfOF1X70XgfI/qYJ80mD6Pdz1ZIiMFNaO6IgJ00Jbc0JIS/HLgtbYNx5R9Q=="><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=https://HoshikawaRyuukou.github.io/images/favicon.ico></head><body class="max-width mx-auto px3 ltr"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick='$("html, body").animate({scrollTop:0},"fast")' style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/about>About</a></li></ul></span><br><span id=actions><ul><li><a class=icon href=https://HoshikawaRyuukou.github.io/posts/software-design-principle-inversion-of-control-ioc/ aria-label=Previous><i class="fas fa-chevron-left" aria-hidden=true onmouseover='$("#i-prev").toggle()' onmouseout='$("#i-prev").toggle()'></i></a></li><li><a class=icon href=https://HoshikawaRyuukou.github.io/posts/unity-platform-web/ aria-label=Next><i class="fas fa-chevron-right" aria-hidden=true onmouseover='$("#i-next").toggle()' onmouseout='$("#i-next").toggle()'></i></a></li><li><a class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up" aria-hidden=true onmouseover='$("#i-top").toggle()' onmouseout='$("#i-top").toggle()'></i></a></li><li><a class=icon href=# aria-label=Share><i class="fas fa-share-alt" aria-hidden=true onmouseover='$("#i-share").toggle()' onmouseout='$("#i-share").toggle()' onclick='return $("#share").toggle(),!1'></i></a></li></ul><span id=i-prev class=info style=display:none>Previous post</span>
<span id=i-next class=info style=display:none>Next post</span>
<span id=i-top class=info style=display:none>Back to top</span>
<span id=i-share class=info style=display:none>Share post</span></span><br><div id=share style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f" aria-label=Facebook><i class="fab fa-facebook" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&text=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label=Twitter><i class="fab fa-twitter" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&title=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label=Linkedin><i class="fab fa-linkedin" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&is_video=false&description=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label=Pinterest><i class="fab fa-pinterest" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok&body=Check out this article: https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f" aria-label=Email><i class="fas fa-envelope" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&title=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label=Pocket><i class="fab fa-get-pocket" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&title=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label=reddit><i class="fab fa-reddit" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&name=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok&description=Quick%20Chat%20%e5%8f%83%e8%80%83%e4%bb%a5%e4%b8%8b%e6%95%99%e5%ad%b8%0a%e5%8d%81%e5%88%86%e9%92%9f%e9%83%a8%e7%bd%b2%e6%9c%ac%e5%9c%b0%e7%a6%bb%e7%ba%bf%e5%85%8d%e8%b4%b9%e5%a4%a7%e6%a8%a1%e5%9e%8b%ef%bc%81%20Ngrok%20%2b%20Ollama%20%7c%20%e5%9c%a8%e4%b8%96%e7%95%8c%e4%bb%bb%e4%bd%95%e5%9c%b0%e6%96%b9%e4%b8%8elocalhost%e5%bc%80%e6%ba%90%e5%a4%a7%e6%a8%a1%e5%9e%8b%e8%81%8a%e5%a4%a9%20Free%20Inference%20Is%20All%20I%20Need%3a%20How%20to%20Run%20Large%20Language%20Models%20for%20Free%20Using%20Google%20Colab%20Requirements%20%e8%a8%bb%e5%86%8a%20ngrok%20%e5%b8%b3%e8%99%9f%ef%bc%8c%e5%8f%96%e5%be%97%20token%20%28%20ngrok%20%26gt%3b%20Your%20Authtoken%20%29%20%e5%b0%87%20token%20%e5%a1%ab%e8%87%b3%20colab%20%26gt%3b%20Secret%20name%20%3a%20NGROK_AUTH%20value%20%3a%20token%20%e6%9c%ac%e6%a9%9f%e7%ab%af%e4%bd%bf%e7%94%a8%20Page%20Assist%20-%20A%20Web%20UI%20for%20Local%20AI%20Models%20%e8%88%87%20Ollama%20%e4%ba%92%e5%8b%95%20Steps%20%e5%ae%89%e8%a3%9d%e5%bf%85%e8%a6%81%e5%b7%a5%e5%85%b7%20%21sudo%20apt-get%20install%20-y%20pciutils%20%21" aria-label=Tumblr><i class="fab fa-tumblr" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&t=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label="Hacker News"><i class="fab fa-hacker-news" aria-hidden=true></i></a></li></ul></div><div id=toc><nav id=TableOfContents><ul><li><a href=#quick-chat>Quick Chat</a></li><li><a href=#requirements>Requirements</a></li><li><a href=#steps>Steps</a><ul><li><a href=#安裝必要工具>安裝必要工具</a></li><li><a href=#啟動-ollama-服務器>啟動 Ollama 服務器</a></li><li><a href=#下載模型>下載模型</a></li><li><a href=#公開服務>公開服務</a></li><li><a href=#列出可用模型>列出可用模型</a></li><li><a href=#執行模型>執行模型</a></li><li><a href=#透過-page-assist-訪問>透過 Page Assist 訪問</a></li></ul></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">AI - Ollama - Google Colab + ngrok</h1><div class=meta><div class=postdate><time datetime="2025-01-16 21:11:00 +0000 UTC" itemprop=datePublished>2025-01-16</time></div><div class=article-tag><i class="fas fa-tag"></i>
<a class=tag-link href=/tags/ai rel=tag>AI</a>
,
<a class=tag-link href=/tags/ollama rel=tag>Ollama</a>
,
<a class=tag-link href=/tags/google-colab rel=tag>Google Colab</a>
,
<a class=tag-link href=/tags/ngrok rel=tag>ngrok</a></div></div></header><div class=content itemprop=articleBody><h2 id=quick-chat>Quick Chat</h2><p>參考以下教學</p><ul><li><a href="https://www.youtube.com/watch?v=ZOCY61424JI">十分钟部署本地离线免费大模型！</a></li><li><a href="https://www.youtube.com/watch?v=JfI3K3HwQuI">Ngrok + Ollama | 在世界任何地方与localhost开源大模型聊天</a></li><li><a href=https://blog.gopenai.com/free-inference-is-all-i-need-how-to-run-large-language-models-for-free-using-google-colab-fe961e86503b>Free Inference Is All I Need: How to Run Large Language Models for Free Using Google Colab</a></li></ul><h2 id=requirements>Requirements</h2><ul><li>註冊 <a href=https://ngrok.com/>ngrok</a> 帳號，取得 token ( ngrok > Your Authtoken )</li><li>將 token 填至 colab > Secret<ul><li>name : NGROK_AUTH</li><li>value : token</li></ul></li><li>本機端使用 <a href=https://chromewebstore.google.com/detail/page-assist-a-web-ui-for/jfgfiigpkhlkbnfnbobbkinehhfdhndo>Page Assist - A Web UI for Local AI Models</a> 與 Ollama 互動</li></ul><h2 id=steps>Steps</h2><h3 id=安裝必要工具>安裝必要工具</h3><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>!sudo apt-get install -y pciutils
</span></span><span style=display:flex><span>!curl https://ollama.ai/install.sh <span style=color:#111>|</span> sh
</span></span><span style=display:flex><span>!pip install pyngrok
</span></span></code></pre></div><ul><li><strong>安裝 pciutils</strong>: 提供硬件檢測和配置工具，用於檢查和診斷 GPU 設置。</li><li><strong>安裝 Ollama</strong>: 下載並執行 Ollama 的安裝腳本。</li><li><strong>安裝 pyngrok</strong>: 用於創建到本地服務的反向代理，從而將本地服務器公開到互聯網。</li></ul><h3 id=啟動-ollama-服務器>啟動 Ollama 服務器</h3><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>os</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>threading</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>subprocess</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>requests</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>pyngrok</span> <span style=color:#f92672>import</span> <span style=color:#111>ngrok</span><span style=color:#111>,</span> <span style=color:#111>conf</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>google.colab</span> <span style=color:#f92672>import</span> <span style=color:#111>userdata</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#00a8c8>def</span> <span style=color:#75af00>ollama</span><span style=color:#111>():</span>
</span></span><span style=display:flex><span>    <span style=color:#111>os</span><span style=color:#f92672>.</span><span style=color:#111>environ</span><span style=color:#111>[</span><span style=color:#d88200>&#39;OLLAMA_HOST&#39;</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#39;0.0.0.0:11434&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#111>os</span><span style=color:#f92672>.</span><span style=color:#111>environ</span><span style=color:#111>[</span><span style=color:#d88200>&#39;OLLAMA_ORIGINS&#39;</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#39;*&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#111>os</span><span style=color:#f92672>.</span><span style=color:#111>environ</span><span style=color:#111>[</span><span style=color:#d88200>&#39;OLLAMA_KEEP_ALIVE&#39;</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#39;-1&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#111>subprocess</span><span style=color:#f92672>.</span><span style=color:#111>Popen</span><span style=color:#111>([</span><span style=color:#d88200>&#34;ollama&#34;</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;serve&#34;</span><span style=color:#111>])</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>ollama_thread</span> <span style=color:#f92672>=</span> <span style=color:#111>threading</span><span style=color:#f92672>.</span><span style=color:#111>Thread</span><span style=color:#111>(</span><span style=color:#111>target</span><span style=color:#f92672>=</span><span style=color:#111>ollama</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>ollama_thread</span><span style=color:#f92672>.</span><span style=color:#111>start</span><span style=color:#111>()</span>
</span></span></code></pre></div><ul><li><strong>配置環境變量</strong>：<ul><li>OLLAMA_HOST: 指定服務器的主機和端口，這裡為 0.0.0.0:11434，表示本地所有網絡接口。</li><li>OLLAMA_ORIGINS: 設置跨域資源共享 (CORS) 的允許範圍。</li><li>OLLAMA_KEEP_ALIVE: 保持服務器活躍的時長（-1 表示無限）。</li></ul></li><li><strong>啟動 Ollama 服務器</strong>：使用 subprocess 啟動 Ollama 的服務模式。</li><li><strong>使用執行緒運行服務器</strong>：確保主程序不被阻塞，允許服務器在後台運行。</li></ul><h3 id=下載模型>下載模型</h3><ul><li><a href=https://ollama.com/search>Ollama search</a></li></ul><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>!ollama pull <span style=color:#f92672>{</span>model_name<span style=color:#f92672>}</span>
</span></span></code></pre></div><h3 id=公開服務>公開服務</h3><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#111>conf</span><span style=color:#f92672>.</span><span style=color:#111>get_default</span><span style=color:#111>()</span><span style=color:#f92672>.</span><span style=color:#111>auth_token</span> <span style=color:#f92672>=</span> <span style=color:#111>userdata</span><span style=color:#f92672>.</span><span style=color:#111>get</span><span style=color:#111>(</span><span style=color:#d88200>&#39;NGROK_AUTH&#39;</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>ollama_tunnel</span> <span style=color:#f92672>=</span> <span style=color:#111>ngrok</span><span style=color:#f92672>.</span><span style=color:#111>connect</span><span style=color:#111>(</span><span style=color:#d88200>&#34;11434&#34;</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;http&#34;</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>public_url</span> <span style=color:#f92672>=</span> <span style=color:#111>ollama_tunnel</span><span style=color:#f92672>.</span><span style=color:#111>public_url</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#d88200>f</span><span style=color:#d88200>&#34;Public URL: </span><span style=color:#d88200>{</span><span style=color:#111>public_url</span><span style=color:#d88200>}</span><span style=color:#d88200>&#34;</span><span style=color:#111>)</span>
</span></span></code></pre></div><ul><li><strong>配置 ngrok 驗證令牌</strong>：使用用戶提供的 NGROK_AUTH 確保 Tunnel 服務的授權。</li><li><strong>創建 ngrok Tunnel</strong>： 將本地服務器（11434 端口）通過 HTTP 隧道公開到互聯網。</li><li><strong>獲取公開 URL</strong>： 輸出 Tunnel 的公開 URL，便於遠程訪問 Ollama 服務。</li></ul><h3 id=列出可用模型>列出可用模型</h3><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>!ollama list
</span></span></code></pre></div><h3 id=執行模型>執行模型</h3><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>!ollama run <span style=color:#f92672>{</span>model_name<span style=color:#f92672>}</span>
</span></span></code></pre></div><h3 id=透過-page-assist-訪問>透過 Page Assist 訪問</h3><ul><li>於 Page Assist 設置 public_url</li><li>訪問 public_url 並點擊 visit site，否則 Page Assist 偵測不到遠端 ollama</li></ul></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/about>About</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#quick-chat>Quick Chat</a></li><li><a href=#requirements>Requirements</a></li><li><a href=#steps>Steps</a><ul><li><a href=#安裝必要工具>安裝必要工具</a></li><li><a href=#啟動-ollama-服務器>啟動 Ollama 服務器</a></li><li><a href=#下載模型>下載模型</a></li><li><a href=#公開服務>公開服務</a></li><li><a href=#列出可用模型>列出可用模型</a></li><li><a href=#執行模型>執行模型</a></li><li><a href=#透過-page-assist-訪問>透過 Page Assist 訪問</a></li></ul></li></ul></nav></div><div id=share-footer style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f" aria-label=Facebook><i class="fab fa-facebook fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&text=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label=Twitter><i class="fab fa-twitter fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&title=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label=Linkedin><i class="fab fa-linkedin fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&is_video=false&description=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label=Pinterest><i class="fab fa-pinterest fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok&body=Check out this article: https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f" aria-label=Email><i class="fas fa-envelope fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&title=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label=Pocket><i class="fab fa-get-pocket fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&title=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label=reddit><i class="fab fa-reddit fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&name=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok&description=Quick%20Chat%20%e5%8f%83%e8%80%83%e4%bb%a5%e4%b8%8b%e6%95%99%e5%ad%b8%0a%e5%8d%81%e5%88%86%e9%92%9f%e9%83%a8%e7%bd%b2%e6%9c%ac%e5%9c%b0%e7%a6%bb%e7%ba%bf%e5%85%8d%e8%b4%b9%e5%a4%a7%e6%a8%a1%e5%9e%8b%ef%bc%81%20Ngrok%20%2b%20Ollama%20%7c%20%e5%9c%a8%e4%b8%96%e7%95%8c%e4%bb%bb%e4%bd%95%e5%9c%b0%e6%96%b9%e4%b8%8elocalhost%e5%bc%80%e6%ba%90%e5%a4%a7%e6%a8%a1%e5%9e%8b%e8%81%8a%e5%a4%a9%20Free%20Inference%20Is%20All%20I%20Need%3a%20How%20to%20Run%20Large%20Language%20Models%20for%20Free%20Using%20Google%20Colab%20Requirements%20%e8%a8%bb%e5%86%8a%20ngrok%20%e5%b8%b3%e8%99%9f%ef%bc%8c%e5%8f%96%e5%be%97%20token%20%28%20ngrok%20%26gt%3b%20Your%20Authtoken%20%29%20%e5%b0%87%20token%20%e5%a1%ab%e8%87%b3%20colab%20%26gt%3b%20Secret%20name%20%3a%20NGROK_AUTH%20value%20%3a%20token%20%e6%9c%ac%e6%a9%9f%e7%ab%af%e4%bd%bf%e7%94%a8%20Page%20Assist%20-%20A%20Web%20UI%20for%20Local%20AI%20Models%20%e8%88%87%20Ollama%20%e4%ba%92%e5%8b%95%20Steps%20%e5%ae%89%e8%a3%9d%e5%bf%85%e8%a6%81%e5%b7%a5%e5%85%b7%20%21sudo%20apt-get%20install%20-y%20pciutils%20%21" aria-label=Tumblr><i class="fab fa-tumblr fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-google-colab-%2b-ngrok%2f&t=AI%20-%20Ollama%20-%20Google%20Colab%20%2b%20ngrok" aria-label="Hacker News"><i class="fab fa-hacker-news fa-lg" aria-hidden=true></i></a></li></ul></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick='return $("#nav-footer").toggle(),!1' aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick='return $("#toc-footer").toggle(),!1' aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick='return $("#share-footer").toggle(),!1' aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2025 HoshikawaRyuukou</div><div class=footer-right><nav><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/about>About</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=/lib/font-awesome/css/all.min.css><script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>
<script src=/js/code-copy.js></script></html>