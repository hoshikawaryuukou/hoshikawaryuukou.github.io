<!doctype html><html lang=zh-tw><head><link rel=preload href=/lib/font-awesome/webfonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/font-awesome/webfonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/font-awesome/webfonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><script type=text/javascript src=https://latest.cactus.chat/cactus.js></script>
<link rel=stylesheet href=https://latest.cactus.chat/style.css type=text/css><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>AI - Ollama - Note | 識之箱庭</title><link rel=canonical href=https://HoshikawaRyuukou.github.io/posts/ai-ollama-note/><meta name=description content="紙上得來終覺淺，絕知此事要躬行。"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="AI - Ollama - Note"><meta property="og:description" content="Guide Ollama UI Page Assist - A Web UI for Local AI Models Commands ollama list : 查看以配置本地模型 ollama run {model} : 下載/執行模型 ollama ps : 展示目前載入的模型、它們所佔的記憶體大小以及所使用的處理器類型（GPU 或 CPU） Use model from Ollama Ollama search Use GGUF model from Hugging Face Hub # Run Ollama with specified model # ollama run hf.co/{username}/{repository} ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF # Run Ollama with specified model and desired quantization # ollama run hf.co/{username}/{repository}:{quantization} ollama run hf."><meta property="og:type" content="article"><meta property="og:url" content="https://HoshikawaRyuukou.github.io/posts/ai-ollama-note/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-19T21:11:00+00:00"><meta property="article:modified_time" content="2024-08-19T21:11:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI - Ollama - Note"><meta name=twitter:description content="Guide Ollama UI Page Assist - A Web UI for Local AI Models Commands ollama list : 查看以配置本地模型 ollama run {model} : 下載/執行模型 ollama ps : 展示目前載入的模型、它們所佔的記憶體大小以及所使用的處理器類型（GPU 或 CPU） Use model from Ollama Ollama search Use GGUF model from Hugging Face Hub # Run Ollama with specified model # ollama run hf.co/{username}/{repository} ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF # Run Ollama with specified model and desired quantization # ollama run hf.co/{username}/{repository}:{quantization} ollama run hf."><link rel=stylesheet href=https://HoshikawaRyuukou.github.io/css/styles.9293a5aa5b416dbdce7874b0376fe51f0f87bf229c7ce1755fbd1781f23fa9827cd260fa3ddcf564888c14d68ee88809d3425b7342484bf1cb82d6d8371e51f5.css integrity="sha512-kpOlqltBbb3OeHSwN2/lHw+HvyKcfOF1X70XgfI/qYJ80mD6Pdz1ZIiMFNaO6IgJ00Jbc0JIS/HLgtbYNx5R9Q=="><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=https://HoshikawaRyuukou.github.io/images/favicon.ico></head><body class="max-width mx-auto px3 ltr"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick='$("html, body").animate({scrollTop:0},"fast")' style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/about>About</a></li></ul></span><br><span id=actions><ul><li><a class=icon href=https://HoshikawaRyuukou.github.io/posts/software-development-repository-structure-note/ aria-label=Previous><i class="fas fa-chevron-left" aria-hidden=true onmouseover='$("#i-prev").toggle()' onmouseout='$("#i-prev").toggle()'></i></a></li><li><a class=icon href=https://HoshikawaRyuukou.github.io/posts/software-development-sites/ aria-label=Next><i class="fas fa-chevron-right" aria-hidden=true onmouseover='$("#i-next").toggle()' onmouseout='$("#i-next").toggle()'></i></a></li><li><a class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up" aria-hidden=true onmouseover='$("#i-top").toggle()' onmouseout='$("#i-top").toggle()'></i></a></li><li><a class=icon href=# aria-label=Share><i class="fas fa-share-alt" aria-hidden=true onmouseover='$("#i-share").toggle()' onmouseout='$("#i-share").toggle()' onclick='return $("#share").toggle(),!1'></i></a></li></ul><span id=i-prev class=info style=display:none>Previous post</span>
<span id=i-next class=info style=display:none>Next post</span>
<span id=i-top class=info style=display:none>Back to top</span>
<span id=i-share class=info style=display:none>Share post</span></span><br><div id=share style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f" aria-label=Facebook><i class="fab fa-facebook" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&text=AI%20-%20Ollama%20-%20Note" aria-label=Twitter><i class="fab fa-twitter" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&title=AI%20-%20Ollama%20-%20Note" aria-label=Linkedin><i class="fab fa-linkedin" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&is_video=false&description=AI%20-%20Ollama%20-%20Note" aria-label=Pinterest><i class="fab fa-pinterest" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=AI%20-%20Ollama%20-%20Note&body=Check out this article: https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f" aria-label=Email><i class="fas fa-envelope" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&title=AI%20-%20Ollama%20-%20Note" aria-label=Pocket><i class="fab fa-get-pocket" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&title=AI%20-%20Ollama%20-%20Note" aria-label=reddit><i class="fab fa-reddit" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&name=AI%20-%20Ollama%20-%20Note&description=Guide%20Ollama%20UI%20Page%20Assist%20-%20A%20Web%20UI%20for%20Local%20AI%20Models%20Commands%20ollama%20list%20%3a%20%e6%9f%a5%e7%9c%8b%e4%bb%a5%e9%85%8d%e7%bd%ae%e6%9c%ac%e5%9c%b0%e6%a8%a1%e5%9e%8b%20ollama%20run%20%7bmodel%7d%20%3a%20%e4%b8%8b%e8%bc%89%2f%e5%9f%b7%e8%a1%8c%e6%a8%a1%e5%9e%8b%20ollama%20ps%20%3a%20%e5%b1%95%e7%a4%ba%e7%9b%ae%e5%89%8d%e8%bc%89%e5%85%a5%e7%9a%84%e6%a8%a1%e5%9e%8b%e3%80%81%e5%ae%83%e5%80%91%e6%89%80%e4%bd%94%e7%9a%84%e8%a8%98%e6%86%b6%e9%ab%94%e5%a4%a7%e5%b0%8f%e4%bb%a5%e5%8f%8a%e6%89%80%e4%bd%bf%e7%94%a8%e7%9a%84%e8%99%95%e7%90%86%e5%99%a8%e9%a1%9e%e5%9e%8b%ef%bc%88GPU%20%e6%88%96%20CPU%ef%bc%89%20Use%20model%20from%20Ollama%20Ollama%20search%20Use%20GGUF%20model%20from%20Hugging%20Face%20Hub%20%23%20Run%20Ollama%20with%20specified%20model%20%23%20ollama%20run%20hf.co%2f%7busername%7d%2f%7brepository%7d%20ollama%20run%20hf.co%2fbartowski%2fLlama-3.2-3B-Instruct-GGUF%20%23%20Run%20Ollama%20with%20specified%20model%20and%20desired%20quantization%20%23%20ollama%20run%20hf.co%2f%7busername%7d%2f%7brepository%7d%3a%7bquantization%7d%20ollama%20run%20hf." aria-label=Tumblr><i class="fab fa-tumblr" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&t=AI%20-%20Ollama%20-%20Note" aria-label="Hacker News"><i class="fab fa-hacker-news" aria-hidden=true></i></a></li></ul></div><div id=toc><nav id=TableOfContents><ul><li><a href=#guide>Guide</a></li><li><a href=#ui>UI</a></li><li><a href=#commands>Commands</a></li><li><a href=#use-model-from-ollama>Use model from Ollama</a></li><li><a href=#use-gguf-model-from-hugging-face-hub>Use GGUF model from Hugging Face Hub</a></li><li><a href=#use-gguf-model-from-local>Use GGUF model from local</a><ul><li><a href=#import_gguf_to_ollamabat>import_gguf_to_ollama.bat</a></li></ul></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">AI - Ollama - Note</h1><div class=meta><div class=postdate><time datetime="2024-08-19 21:11:00 +0000 UTC" itemprop=datePublished>2024-08-19</time></div><div class=article-tag><i class="fas fa-tag"></i>
<a class=tag-link href=/tags/ai rel=tag>AI</a>
,
<a class=tag-link href=/tags/ollama rel=tag>Ollama</a></div></div></header><div class=content itemprop=articleBody><h2 id=guide>Guide</h2><ul><li><a href=https://ollama.com/>Ollama</a></li></ul><h2 id=ui>UI</h2><ul><li><a href=https://chromewebstore.google.com/detail/page-assist-a-web-ui-for/jfgfiigpkhlkbnfnbobbkinehhfdhndo>Page Assist - A Web UI for Local AI Models</a></li></ul><h2 id=commands>Commands</h2><ul><li>ollama list : 查看以配置本地模型</li><li>ollama run {model} : 下載/執行模型</li><li>ollama ps : 展示目前載入的模型、它們所佔的記憶體大小以及所使用的處理器類型（GPU 或 CPU）</li></ul><h2 id=use-model-from-ollama>Use model from Ollama</h2><ul><li><a href=https://ollama.com/search>Ollama search</a></li></ul><h2 id=use-gguf-model-from-hugging-face-hub>Use GGUF model from Hugging Face Hub</h2><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Run Ollama with specified model</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ollama run hf.co/{username}/{repository}</span>
</span></span><span style=display:flex><span>ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Run Ollama with specified model and desired quantization</span>
</span></span><span style=display:flex><span><span style=color:#75715e># ollama run hf.co/{username}/{repository}:{quantization}</span>
</span></span><span style=display:flex><span>ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:IQ3_M
</span></span></code></pre></div><h2 id=use-gguf-model-from-local>Use GGUF model from local</h2><h3 id=import_gguf_to_ollamabat>import_gguf_to_ollama.bat</h3><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bat data-lang=bat><span style=display:flex><span><span style=color:#111>@</span><span style=color:#00a8c8>echo</span> off
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>REM 設定本地環境，並切換到批次檔所在的目錄</span>
</span></span><span style=display:flex><span><span style=color:#00a8c8>setlocal</span>
</span></span><span style=display:flex><span><span style=color:#00a8c8>cd</span> /d <span style=color:#111>%~dp0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>REM 搜尋當前目錄中的 .gguf 檔案</span>
</span></span><span style=display:flex><span><span style=color:#00a8c8>for</span> <span style=color:#8045ff>%%</span>f <span style=color:#00a8c8>in</span> <span style=color:#111>(</span>*.gguf<span style=color:#111>)</span> <span style=color:#00a8c8>do</span> <span style=color:#111>(</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>REM 創建 Modelfile.txt 並寫入模型檔案名稱</span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>echo</span> FROM <span style=color:#8045ff>%%</span>~nf.gguf <span style=color:#111>&gt;</span> Modelfile.txt
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>REM 打印 Modelfile.txt 的內容以供確認</span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>type</span> Modelfile.txt
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>REM 執行 ollama create 命令來包裝模型檔</span>
</span></span><span style=display:flex><span>    ollama create <span style=color:#8045ff>%%</span>~nf -f Modelfile.txt
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>REM 刪除 Modelfile.txt</span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>del</span> Modelfile.txt
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e>REM 如果有多個 gguf 檔案，只處理第一個找到的檔案</span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>goto</span> <span style=color:#111>end</span>
</span></span><span style=display:flex><span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>:</span><span style=color:#111>end</span>
</span></span><span style=display:flex><span><span style=color:#75715e>REM 顯示完成訊息</span>
</span></span><span style=display:flex><span><span style=color:#00a8c8>echo</span> done...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>REM 列出已經存在的模型</span>
</span></span><span style=display:flex><span>ollama list 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>REM 等待用戶確認並關閉</span>
</span></span><span style=display:flex><span><span style=color:#00a8c8>pause</span> <span style=color:#111>&gt;</span>nul
</span></span></code></pre></div></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/about>About</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#guide>Guide</a></li><li><a href=#ui>UI</a></li><li><a href=#commands>Commands</a></li><li><a href=#use-model-from-ollama>Use model from Ollama</a></li><li><a href=#use-gguf-model-from-hugging-face-hub>Use GGUF model from Hugging Face Hub</a></li><li><a href=#use-gguf-model-from-local>Use GGUF model from local</a><ul><li><a href=#import_gguf_to_ollamabat>import_gguf_to_ollama.bat</a></li></ul></li></ul></nav></div><div id=share-footer style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f" aria-label=Facebook><i class="fab fa-facebook fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&text=AI%20-%20Ollama%20-%20Note" aria-label=Twitter><i class="fab fa-twitter fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&title=AI%20-%20Ollama%20-%20Note" aria-label=Linkedin><i class="fab fa-linkedin fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&is_video=false&description=AI%20-%20Ollama%20-%20Note" aria-label=Pinterest><i class="fab fa-pinterest fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=AI%20-%20Ollama%20-%20Note&body=Check out this article: https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f" aria-label=Email><i class="fas fa-envelope fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&title=AI%20-%20Ollama%20-%20Note" aria-label=Pocket><i class="fab fa-get-pocket fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&title=AI%20-%20Ollama%20-%20Note" aria-label=reddit><i class="fab fa-reddit fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&name=AI%20-%20Ollama%20-%20Note&description=Guide%20Ollama%20UI%20Page%20Assist%20-%20A%20Web%20UI%20for%20Local%20AI%20Models%20Commands%20ollama%20list%20%3a%20%e6%9f%a5%e7%9c%8b%e4%bb%a5%e9%85%8d%e7%bd%ae%e6%9c%ac%e5%9c%b0%e6%a8%a1%e5%9e%8b%20ollama%20run%20%7bmodel%7d%20%3a%20%e4%b8%8b%e8%bc%89%2f%e5%9f%b7%e8%a1%8c%e6%a8%a1%e5%9e%8b%20ollama%20ps%20%3a%20%e5%b1%95%e7%a4%ba%e7%9b%ae%e5%89%8d%e8%bc%89%e5%85%a5%e7%9a%84%e6%a8%a1%e5%9e%8b%e3%80%81%e5%ae%83%e5%80%91%e6%89%80%e4%bd%94%e7%9a%84%e8%a8%98%e6%86%b6%e9%ab%94%e5%a4%a7%e5%b0%8f%e4%bb%a5%e5%8f%8a%e6%89%80%e4%bd%bf%e7%94%a8%e7%9a%84%e8%99%95%e7%90%86%e5%99%a8%e9%a1%9e%e5%9e%8b%ef%bc%88GPU%20%e6%88%96%20CPU%ef%bc%89%20Use%20model%20from%20Ollama%20Ollama%20search%20Use%20GGUF%20model%20from%20Hugging%20Face%20Hub%20%23%20Run%20Ollama%20with%20specified%20model%20%23%20ollama%20run%20hf.co%2f%7busername%7d%2f%7brepository%7d%20ollama%20run%20hf.co%2fbartowski%2fLlama-3.2-3B-Instruct-GGUF%20%23%20Run%20Ollama%20with%20specified%20model%20and%20desired%20quantization%20%23%20ollama%20run%20hf.co%2f%7busername%7d%2f%7brepository%7d%3a%7bquantization%7d%20ollama%20run%20hf." aria-label=Tumblr><i class="fab fa-tumblr fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai-ollama-note%2f&t=AI%20-%20Ollama%20-%20Note" aria-label="Hacker News"><i class="fab fa-hacker-news fa-lg" aria-hidden=true></i></a></li></ul></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick='return $("#nav-footer").toggle(),!1' aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick='return $("#toc-footer").toggle(),!1' aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick='return $("#share-footer").toggle(),!1' aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2025 HoshikawaRyuukou</div><div class=footer-right><nav><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/about>About</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=/lib/font-awesome/css/all.min.css><script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>
<script src=/js/code-copy.js></script></html>