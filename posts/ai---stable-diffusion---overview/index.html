<!doctype html><html lang=zh-tw><head><link rel=preload href=/lib/font-awesome/webfonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/font-awesome/webfonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/font-awesome/webfonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>AI - Stable diffusion - Overview | 識之箱庭</title><link rel=canonical href=https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---overview/><meta name=description content="紙上得來終覺淺，絕知此事要躬行。"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:url" content="https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---overview/"><meta property="og:site_name" content="識之箱庭"><meta property="og:title" content="AI - Stable diffusion - Overview"><meta property="og:description" content="Quick Chat 建議閱讀順序
AI - Stable diffusion - Environment AI - Stable diffusion - GUI AI - Stable diffusion - Quick Start AI - Stable diffusion - Extensions AI - Stable diffusion - CheckPoints AI - Stable diffusion - Resources Core Working Principles Stable Diffusion 主要包含三個核心技術：
前向擴散（Forward Diffusion） 先從大量圖片資料集中學習圖片特徵。 然後，系統會逐步加入高斯雜訊（Gaussian Noise），使圖片變得模糊、無法辨識。 最後，這個過程會讓圖片變成完全的純雜訊（random noise）。 反向去噪（Reverse Denoising / U-Net） Stable Diffusion 學習如何逆向去噪，一步步從雜訊還原出清晰的圖片。 這部分的關鍵是 U-Net 神經網路架構，它可以在多層次的細節中，捕捉圖片的各種特徵。 文本引導（Text Conditioning / CLIP） Stable Diffusion 之所以能生成符合指令的圖片，是因為它使用了CLIP（Contrastive Language-Image Pretraining）。 CLIP 會將文字轉換成向量表示（latent embeddings），這些向量再指導模型生成符合描述的圖像。 Diagram Improving Diffusion Models as an Alternative To GANs, Part 1"><meta property="og:locale" content="zh_tw"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-02-06T21:11:00+00:00"><meta property="article:modified_time" content="2025-02-06T21:11:00+00:00"><meta property="article:tag" content="AI"><meta property="article:tag" content="Stable Diffusion"><meta property="article:tag" content="Art"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI - Stable diffusion - Overview"><meta name=twitter:description content="Quick Chat 建議閱讀順序
AI - Stable diffusion - Environment AI - Stable diffusion - GUI AI - Stable diffusion - Quick Start AI - Stable diffusion - Extensions AI - Stable diffusion - CheckPoints AI - Stable diffusion - Resources Core Working Principles Stable Diffusion 主要包含三個核心技術：
前向擴散（Forward Diffusion） 先從大量圖片資料集中學習圖片特徵。 然後，系統會逐步加入高斯雜訊（Gaussian Noise），使圖片變得模糊、無法辨識。 最後，這個過程會讓圖片變成完全的純雜訊（random noise）。 反向去噪（Reverse Denoising / U-Net） Stable Diffusion 學習如何逆向去噪，一步步從雜訊還原出清晰的圖片。 這部分的關鍵是 U-Net 神經網路架構，它可以在多層次的細節中，捕捉圖片的各種特徵。 文本引導（Text Conditioning / CLIP） Stable Diffusion 之所以能生成符合指令的圖片，是因為它使用了CLIP（Contrastive Language-Image Pretraining）。 CLIP 會將文字轉換成向量表示（latent embeddings），這些向量再指導模型生成符合描述的圖像。 Diagram Improving Diffusion Models as an Alternative To GANs, Part 1"><link rel=stylesheet href=https://HoshikawaRyuukou.github.io/css/styles.9293a5aa5b416dbdce7874b0376fe51f0f87bf229c7ce1755fbd1781f23fa9827cd260fa3ddcf564888c14d68ee88809d3425b7342484bf1cb82d6d8371e51f5.css integrity="sha512-kpOlqltBbb3OeHSwN2/lHw+HvyKcfOF1X70XgfI/qYJ80mD6Pdz1ZIiMFNaO6IgJ00Jbc0JIS/HLgtbYNx5R9Q=="><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script><script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=https://HoshikawaRyuukou.github.io/images/favicon.ico><script async src="https://www.googletagmanager.com/gtag/js?id=G-GJK533W9NW"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GJK533W9NW")}</script></head><body class="max-width mx-auto px3 ltr"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick='$("html, body").animate({scrollTop:0},"fast")' style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/search/>Search</a></li><li><a href=/about>About</a></li></ul></span><br><span id=actions><ul><li><a class=icon href=https://HoshikawaRyuukou.github.io/posts/unity---performance---render---overdraw/ aria-label=Previous><i class="fas fa-chevron-left" aria-hidden=true onmouseover='$("#i-prev").toggle()' onmouseout='$("#i-prev").toggle()'></i></a></li><li><a class=icon href=https://HoshikawaRyuukou.github.io/posts/game-development---web-game---device-evaluation/ aria-label=Next><i class="fas fa-chevron-right" aria-hidden=true onmouseover='$("#i-next").toggle()' onmouseout='$("#i-next").toggle()'></i></a></li><li><a class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up" aria-hidden=true onmouseover='$("#i-top").toggle()' onmouseout='$("#i-top").toggle()'></i></a></li><li><a class=icon href=# aria-label=Share><i class="fas fa-share-alt" aria-hidden=true onmouseover='$("#i-share").toggle()' onmouseout='$("#i-share").toggle()' onclick='return $("#share").toggle(),!1'></i></a></li></ul><span id=i-prev class=info style=display:none>Previous post</span>
<span id=i-next class=info style=display:none>Next post</span>
<span id=i-top class=info style=display:none>Back to top</span>
<span id=i-share class=info style=display:none>Share post</span></span><br><div id=share style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f" aria-label=Facebook><i class="fab fa-facebook" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&text=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label=Twitter><i class="fab fa-twitter" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&title=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label=Linkedin><i class="fab fa-linkedin" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&is_video=false&description=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label=Pinterest><i class="fab fa-pinterest" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=AI%20-%20Stable%20diffusion%20-%20Overview&body=Check out this article: https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f" aria-label=Email><i class="fas fa-envelope" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&title=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label=Pocket><i class="fab fa-get-pocket" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&title=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label=reddit><i class="fab fa-reddit" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&name=AI%20-%20Stable%20diffusion%20-%20Overview&description=%3ch2%20id%3d%22quick-chat%22%3eQuick%20Chat%3c%2fh2%3e%0a%3cp%3e%e5%bb%ba%e8%ad%b0%e9%96%b1%e8%ae%80%e9%a0%86%e5%ba%8f%3c%2fp%3e%0a%3cul%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20Environment%3c%2fli%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20GUI%3c%2fli%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20Quick%20Start%3c%2fli%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20Extensions%3c%2fli%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20CheckPoints%3c%2fli%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20Resources%3c%2fli%3e%0a%3c%2ful%3e%0a%3ch2%20id%3d%22core-working-principles%22%3eCore%20Working%20Principles%3c%2fh2%3e%0a%3cp%3eStable%20Diffusion%20%e4%b8%bb%e8%a6%81%e5%8c%85%e5%90%ab%e4%b8%89%e5%80%8b%e6%a0%b8%e5%bf%83%e6%8a%80%e8%a1%93%ef%bc%9a%3c%2fp%3e%0a%3ch3%20id%3d%22%e5%89%8d%e5%90%91%e6%93%b4%e6%95%a3forward-diffusion%22%3e%e5%89%8d%e5%90%91%e6%93%b4%e6%95%a3%ef%bc%88Forward%20Diffusion%ef%bc%89%3c%2fh3%3e%0a%3cul%3e%0a%3cli%3e%e5%85%88%e5%be%9e%e5%a4%a7%e9%87%8f%e5%9c%96%e7%89%87%e8%b3%87%e6%96%99%e9%9b%86%e4%b8%ad%e5%ad%b8%e7%bf%92%e5%9c%96%e7%89%87%e7%89%b9%e5%be%b5%e3%80%82%3c%2fli%3e%0a%3cli%3e%e7%84%b6%e5%be%8c%ef%bc%8c%e7%b3%bb%e7%b5%b1%e6%9c%83%e9%80%90%e6%ad%a5%e5%8a%a0%e5%85%a5%e9%ab%98%e6%96%af%e9%9b%9c%e8%a8%8a%ef%bc%88Gaussian%20Noise%ef%bc%89%ef%bc%8c%e4%bd%bf%e5%9c%96%e7%89%87%e8%ae%8a%e5%be%97%e6%a8%a1%e7%b3%8a%e3%80%81%e7%84%a1%e6%b3%95%e8%be%a8%e8%ad%98%e3%80%82%3c%2fli%3e%0a%3cli%3e%e6%9c%80%e5%be%8c%ef%bc%8c%e9%80%99%e5%80%8b%e9%81%8e%e7%a8%8b%e6%9c%83%e8%ae%93%e5%9c%96%e7%89%87%e8%ae%8a%e6%88%90%e5%ae%8c%e5%85%a8%e7%9a%84%e7%b4%94%e9%9b%9c%e8%a8%8a%ef%bc%88random%20noise%ef%bc%89%e3%80%82%3c%2fli%3e%0a%3c%2ful%3e%0a%3ch3%20id%3d%22%e5%8f%8d%e5%90%91%e5%8e%bb%e5%99%aareverse-denoising--u-net%22%3e%e5%8f%8d%e5%90%91%e5%8e%bb%e5%99%aa%ef%bc%88Reverse%20Denoising%20%2f%20U-Net%ef%bc%89%3c%2fh3%3e%0a%3cul%3e%0a%3cli%3eStable%20Diffusion%20%e5%ad%b8%e7%bf%92%e5%a6%82%e4%bd%95%e9%80%86%e5%90%91%e5%8e%bb%e5%99%aa%ef%bc%8c%e4%b8%80%e6%ad%a5%e6%ad%a5%e5%be%9e%e9%9b%9c%e8%a8%8a%e9%82%84%e5%8e%9f%e5%87%ba%e6%b8%85%e6%99%b0%e7%9a%84%e5%9c%96%e7%89%87%e3%80%82%3c%2fli%3e%0a%3cli%3e%e9%80%99%e9%83%a8%e5%88%86%e7%9a%84%e9%97%9c%e9%8d%b5%e6%98%af%20U-Net%20%e7%a5%9e%e7%b6%93%e7%b6%b2%e8%b7%af%e6%9e%b6%e6%a7%8b%ef%bc%8c%e5%ae%83%e5%8f%af%e4%bb%a5%e5%9c%a8%e5%a4%9a%e5%b1%a4%e6%ac%a1%e7%9a%84%e7%b4%b0%e7%af%80%e4%b8%ad%ef%bc%8c%e6%8d%95%e6%8d%89%e5%9c%96%e7%89%87%e7%9a%84%e5%90%84%e7%a8%ae%e7%89%b9%e5%be%b5%e3%80%82%3c%2fli%3e%0a%3c%2ful%3e%0a%3ch3%20id%3d%22%e6%96%87%e6%9c%ac%e5%bc%95%e5%b0%8etext-conditioning--clip%22%3e%e6%96%87%e6%9c%ac%e5%bc%95%e5%b0%8e%ef%bc%88Text%20Conditioning%20%2f%20CLIP%ef%bc%89%3c%2fh3%3e%0a%3cul%3e%0a%3cli%3eStable%20Diffusion%20%e4%b9%8b%e6%89%80%e4%bb%a5%e8%83%bd%e7%94%9f%e6%88%90%e7%ac%a6%e5%90%88%e6%8c%87%e4%bb%a4%e7%9a%84%e5%9c%96%e7%89%87%ef%bc%8c%e6%98%af%e5%9b%a0%e7%82%ba%e5%ae%83%e4%bd%bf%e7%94%a8%e4%ba%86CLIP%ef%bc%88Contrastive%20Language-Image%20Pretraining%ef%bc%89%e3%80%82%3c%2fli%3e%0a%3cli%3eCLIP%20%e6%9c%83%e5%b0%87%e6%96%87%e5%ad%97%e8%bd%89%e6%8f%9b%e6%88%90%e5%90%91%e9%87%8f%e8%a1%a8%e7%a4%ba%ef%bc%88latent%20embeddings%ef%bc%89%ef%bc%8c%e9%80%99%e4%ba%9b%e5%90%91%e9%87%8f%e5%86%8d%e6%8c%87%e5%b0%8e%e6%a8%a1%e5%9e%8b%e7%94%9f%e6%88%90%e7%ac%a6%e5%90%88%e6%8f%8f%e8%bf%b0%e7%9a%84%e5%9c%96%e5%83%8f%e3%80%82%3c%2fli%3e%0a%3c%2ful%3e%0a%3ch3%20id%3d%22diagram%22%3eDiagram%3c%2fh3%3e%0a%3cul%3e%0a%3cli%3e%3ca%20href%3d%22https%3a%2f%2fdeveloper.nvidia.com%2fblog%2fimproving-diffusion-models-as-an-alternative-to-gans-part-1%2f%22%3eImproving%20Diffusion%20Models%20as%20an%20Alternative%20To%20GANs%2c%20Part%201%3c%2fa%3e%3c%2fli%3e%0a%3c%2ful%3e%0a%3cp%3e%0a%20%20%3cimg%20src%3d%22https%3a%2f%2fdeveloper-blogs.nvidia.com%2fwp-content%2fuploads%2f2022%2f04%2fGeneration-with-Diffusion-Models.png%22%20alt%3d%22123%22%3e%0a%0a%3c%2fp%3e" aria-label=Tumblr><i class="fab fa-tumblr" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&t=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label="Hacker News"><i class="fab fa-hacker-news" aria-hidden=true></i></a></li></ul></div><div id=toc><nav id=TableOfContents><ul><li><a href=#quick-chat>Quick Chat</a></li><li><a href=#core-working-principles>Core Working Principles</a><ul><li><a href=#前向擴散forward-diffusion>前向擴散（Forward Diffusion）</a></li><li><a href=#反向去噪reverse-denoising--u-net>反向去噪（Reverse Denoising / U-Net）</a></li><li><a href=#文本引導text-conditioning--clip>文本引導（Text Conditioning / CLIP）</a></li><li><a href=#diagram>Diagram</a></li></ul></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">AI - Stable diffusion - Overview</h1><div class=meta><span class=author itemprop=author itemscope itemtype=http://schema.org/Person><span itemprop=name></span></span><div class=postdate><time datetime="2025-02-06 21:11:00 +0000 UTC" itemprop=datePublished>2025-02-06</time></div><div class=article-tag><i class="fas fa-tag"></i>
<a class=tag-link href=/tags/ai rel=tag>AI</a>
,
<a class=tag-link href=/tags/stable-diffusion rel=tag>Stable diffusion</a>
,
<a class=tag-link href=/tags/art rel=tag>Art</a></div></div></header><div class=content itemprop=articleBody><h2 id=quick-chat>Quick Chat</h2><p>建議閱讀順序</p><ul><li>AI - Stable diffusion - Environment</li><li>AI - Stable diffusion - GUI</li><li>AI - Stable diffusion - Quick Start</li><li>AI - Stable diffusion - Extensions</li><li>AI - Stable diffusion - CheckPoints</li><li>AI - Stable diffusion - Resources</li></ul><h2 id=core-working-principles>Core Working Principles</h2><p>Stable Diffusion 主要包含三個核心技術：</p><h3 id=前向擴散forward-diffusion>前向擴散（Forward Diffusion）</h3><ul><li>先從大量圖片資料集中學習圖片特徵。</li><li>然後，系統會逐步加入高斯雜訊（Gaussian Noise），使圖片變得模糊、無法辨識。</li><li>最後，這個過程會讓圖片變成完全的純雜訊（random noise）。</li></ul><h3 id=反向去噪reverse-denoising--u-net>反向去噪（Reverse Denoising / U-Net）</h3><ul><li>Stable Diffusion 學習如何逆向去噪，一步步從雜訊還原出清晰的圖片。</li><li>這部分的關鍵是 U-Net 神經網路架構，它可以在多層次的細節中，捕捉圖片的各種特徵。</li></ul><h3 id=文本引導text-conditioning--clip>文本引導（Text Conditioning / CLIP）</h3><ul><li>Stable Diffusion 之所以能生成符合指令的圖片，是因為它使用了CLIP（Contrastive Language-Image Pretraining）。</li><li>CLIP 會將文字轉換成向量表示（latent embeddings），這些向量再指導模型生成符合描述的圖像。</li></ul><h3 id=diagram>Diagram</h3><ul><li><a href=https://developer.nvidia.com/blog/improving-diffusion-models-as-an-alternative-to-gans-part-1/>Improving Diffusion Models as an Alternative To GANs, Part 1</a></li></ul><p><img src=https://developer-blogs.nvidia.com/wp-content/uploads/2022/04/Generation-with-Diffusion-Models.png alt=123></p></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/search/>Search</a></li><li><a href=/about>About</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#quick-chat>Quick Chat</a></li><li><a href=#core-working-principles>Core Working Principles</a><ul><li><a href=#前向擴散forward-diffusion>前向擴散（Forward Diffusion）</a></li><li><a href=#反向去噪reverse-denoising--u-net>反向去噪（Reverse Denoising / U-Net）</a></li><li><a href=#文本引導text-conditioning--clip>文本引導（Text Conditioning / CLIP）</a></li><li><a href=#diagram>Diagram</a></li></ul></li></ul></nav></div><div id=share-footer style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f" aria-label=Facebook><i class="fab fa-facebook fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&text=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label=Twitter><i class="fab fa-twitter fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&title=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label=Linkedin><i class="fab fa-linkedin fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&is_video=false&description=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label=Pinterest><i class="fab fa-pinterest fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=AI%20-%20Stable%20diffusion%20-%20Overview&body=Check out this article: https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f" aria-label=Email><i class="fas fa-envelope fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&title=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label=Pocket><i class="fab fa-get-pocket fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&title=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label=reddit><i class="fab fa-reddit fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&name=AI%20-%20Stable%20diffusion%20-%20Overview&description=%3ch2%20id%3d%22quick-chat%22%3eQuick%20Chat%3c%2fh2%3e%0a%3cp%3e%e5%bb%ba%e8%ad%b0%e9%96%b1%e8%ae%80%e9%a0%86%e5%ba%8f%3c%2fp%3e%0a%3cul%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20Environment%3c%2fli%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20GUI%3c%2fli%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20Quick%20Start%3c%2fli%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20Extensions%3c%2fli%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20CheckPoints%3c%2fli%3e%0a%3cli%3eAI%20-%20Stable%20diffusion%20-%20Resources%3c%2fli%3e%0a%3c%2ful%3e%0a%3ch2%20id%3d%22core-working-principles%22%3eCore%20Working%20Principles%3c%2fh2%3e%0a%3cp%3eStable%20Diffusion%20%e4%b8%bb%e8%a6%81%e5%8c%85%e5%90%ab%e4%b8%89%e5%80%8b%e6%a0%b8%e5%bf%83%e6%8a%80%e8%a1%93%ef%bc%9a%3c%2fp%3e%0a%3ch3%20id%3d%22%e5%89%8d%e5%90%91%e6%93%b4%e6%95%a3forward-diffusion%22%3e%e5%89%8d%e5%90%91%e6%93%b4%e6%95%a3%ef%bc%88Forward%20Diffusion%ef%bc%89%3c%2fh3%3e%0a%3cul%3e%0a%3cli%3e%e5%85%88%e5%be%9e%e5%a4%a7%e9%87%8f%e5%9c%96%e7%89%87%e8%b3%87%e6%96%99%e9%9b%86%e4%b8%ad%e5%ad%b8%e7%bf%92%e5%9c%96%e7%89%87%e7%89%b9%e5%be%b5%e3%80%82%3c%2fli%3e%0a%3cli%3e%e7%84%b6%e5%be%8c%ef%bc%8c%e7%b3%bb%e7%b5%b1%e6%9c%83%e9%80%90%e6%ad%a5%e5%8a%a0%e5%85%a5%e9%ab%98%e6%96%af%e9%9b%9c%e8%a8%8a%ef%bc%88Gaussian%20Noise%ef%bc%89%ef%bc%8c%e4%bd%bf%e5%9c%96%e7%89%87%e8%ae%8a%e5%be%97%e6%a8%a1%e7%b3%8a%e3%80%81%e7%84%a1%e6%b3%95%e8%be%a8%e8%ad%98%e3%80%82%3c%2fli%3e%0a%3cli%3e%e6%9c%80%e5%be%8c%ef%bc%8c%e9%80%99%e5%80%8b%e9%81%8e%e7%a8%8b%e6%9c%83%e8%ae%93%e5%9c%96%e7%89%87%e8%ae%8a%e6%88%90%e5%ae%8c%e5%85%a8%e7%9a%84%e7%b4%94%e9%9b%9c%e8%a8%8a%ef%bc%88random%20noise%ef%bc%89%e3%80%82%3c%2fli%3e%0a%3c%2ful%3e%0a%3ch3%20id%3d%22%e5%8f%8d%e5%90%91%e5%8e%bb%e5%99%aareverse-denoising--u-net%22%3e%e5%8f%8d%e5%90%91%e5%8e%bb%e5%99%aa%ef%bc%88Reverse%20Denoising%20%2f%20U-Net%ef%bc%89%3c%2fh3%3e%0a%3cul%3e%0a%3cli%3eStable%20Diffusion%20%e5%ad%b8%e7%bf%92%e5%a6%82%e4%bd%95%e9%80%86%e5%90%91%e5%8e%bb%e5%99%aa%ef%bc%8c%e4%b8%80%e6%ad%a5%e6%ad%a5%e5%be%9e%e9%9b%9c%e8%a8%8a%e9%82%84%e5%8e%9f%e5%87%ba%e6%b8%85%e6%99%b0%e7%9a%84%e5%9c%96%e7%89%87%e3%80%82%3c%2fli%3e%0a%3cli%3e%e9%80%99%e9%83%a8%e5%88%86%e7%9a%84%e9%97%9c%e9%8d%b5%e6%98%af%20U-Net%20%e7%a5%9e%e7%b6%93%e7%b6%b2%e8%b7%af%e6%9e%b6%e6%a7%8b%ef%bc%8c%e5%ae%83%e5%8f%af%e4%bb%a5%e5%9c%a8%e5%a4%9a%e5%b1%a4%e6%ac%a1%e7%9a%84%e7%b4%b0%e7%af%80%e4%b8%ad%ef%bc%8c%e6%8d%95%e6%8d%89%e5%9c%96%e7%89%87%e7%9a%84%e5%90%84%e7%a8%ae%e7%89%b9%e5%be%b5%e3%80%82%3c%2fli%3e%0a%3c%2ful%3e%0a%3ch3%20id%3d%22%e6%96%87%e6%9c%ac%e5%bc%95%e5%b0%8etext-conditioning--clip%22%3e%e6%96%87%e6%9c%ac%e5%bc%95%e5%b0%8e%ef%bc%88Text%20Conditioning%20%2f%20CLIP%ef%bc%89%3c%2fh3%3e%0a%3cul%3e%0a%3cli%3eStable%20Diffusion%20%e4%b9%8b%e6%89%80%e4%bb%a5%e8%83%bd%e7%94%9f%e6%88%90%e7%ac%a6%e5%90%88%e6%8c%87%e4%bb%a4%e7%9a%84%e5%9c%96%e7%89%87%ef%bc%8c%e6%98%af%e5%9b%a0%e7%82%ba%e5%ae%83%e4%bd%bf%e7%94%a8%e4%ba%86CLIP%ef%bc%88Contrastive%20Language-Image%20Pretraining%ef%bc%89%e3%80%82%3c%2fli%3e%0a%3cli%3eCLIP%20%e6%9c%83%e5%b0%87%e6%96%87%e5%ad%97%e8%bd%89%e6%8f%9b%e6%88%90%e5%90%91%e9%87%8f%e8%a1%a8%e7%a4%ba%ef%bc%88latent%20embeddings%ef%bc%89%ef%bc%8c%e9%80%99%e4%ba%9b%e5%90%91%e9%87%8f%e5%86%8d%e6%8c%87%e5%b0%8e%e6%a8%a1%e5%9e%8b%e7%94%9f%e6%88%90%e7%ac%a6%e5%90%88%e6%8f%8f%e8%bf%b0%e7%9a%84%e5%9c%96%e5%83%8f%e3%80%82%3c%2fli%3e%0a%3c%2ful%3e%0a%3ch3%20id%3d%22diagram%22%3eDiagram%3c%2fh3%3e%0a%3cul%3e%0a%3cli%3e%3ca%20href%3d%22https%3a%2f%2fdeveloper.nvidia.com%2fblog%2fimproving-diffusion-models-as-an-alternative-to-gans-part-1%2f%22%3eImproving%20Diffusion%20Models%20as%20an%20Alternative%20To%20GANs%2c%20Part%201%3c%2fa%3e%3c%2fli%3e%0a%3c%2ful%3e%0a%3cp%3e%0a%20%20%3cimg%20src%3d%22https%3a%2f%2fdeveloper-blogs.nvidia.com%2fwp-content%2fuploads%2f2022%2f04%2fGeneration-with-Diffusion-Models.png%22%20alt%3d%22123%22%3e%0a%0a%3c%2fp%3e" aria-label=Tumblr><i class="fab fa-tumblr fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fHoshikawaRyuukou.github.io%2fposts%2fai---stable-diffusion---overview%2f&t=AI%20-%20Stable%20diffusion%20-%20Overview" aria-label="Hacker News"><i class="fab fa-hacker-news fa-lg" aria-hidden=true></i></a></li></ul></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick='return $("#nav-footer").toggle(),!1' aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick='return $("#toc-footer").toggle(),!1' aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick='return $("#share-footer").toggle(),!1' aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2025 HoshikawaRyuukou</div><div class=footer-right><nav><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/search/>Search</a></li><li><a href=/about>About</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=/lib/font-awesome/css/all.min.css><script src=/lib/jquery/jquery.min.js></script><script src=/js/main.js></script><script src=/js/code-copy.js></script></html>