<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on 識之箱庭</title><link>https://HoshikawaRyuukou.github.io/tags/ai/</link><description>Recent content in AI on 識之箱庭</description><generator>Hugo</generator><language>zh-tw</language><copyright>HoshikawaRyuukou</copyright><lastBuildDate>Thu, 08 May 2025 13:11:00 +0000</lastBuildDate><atom:link href="https://HoshikawaRyuukou.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>AI - LLM - Gemini</title><link>https://HoshikawaRyuukou.github.io/posts/ai---llm---gemini/</link><pubDate>Thu, 08 May 2025 13:11:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---llm---gemini/</guid><description>&lt;h2 id="quick-chat">Quick Chat&lt;/h2>
&lt;p>😊 免費方案對於輕度開發綽綽有餘&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=3jdhFHgvxpg">Gemini新手教学&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ai.google.dev/gemini-api/docs?hl=zh-tw">Gemini API  |  Google AI for Developers&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ai.google.dev/gemini-api/docs/pricing?hl=zh-tw&amp;amp;_gl=1*1bgoxhp*_up*MQ..&amp;amp;gclid=CjwKCAiAopuvBhBCEiwAm8jaMRbEEnIJr7BCEthg7psSBoIKbpA9CmArCYnFF-oHxtxYB-4PtmvykRoC120QAvD_BwE">定價  |  Gemini API  |  Google AI for Developers&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ai.google.dev/gemini-api/docs/rate-limits?hl=zh-tw&amp;amp;_gl=1*hth47i*_up*MQ..&amp;amp;gclid=CjwKCAiAopuvBhBCEiwAm8jaMRbEEnIJr7BCEthg7psSBoIKbpA9CmArCYnFF-oHxtxYB-4PtmvykRoC120QAvD_BwE">頻率限制  |  Gemini API  |  Google AI for Developers&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="api">API&lt;/h2>
&lt;ul>
&lt;li>透過 Google AI Studio &lt;a href="https://aistudio.google.com/apikey">申請&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="hello-world">Hello World&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-js" data-lang="js">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00a8c8">import&lt;/span> &lt;span style="color:#111">{&lt;/span> &lt;span style="color:#75af00">GoogleGenAI&lt;/span> &lt;span style="color:#111">}&lt;/span> &lt;span style="color:#75af00">from&lt;/span> &lt;span style="color:#d88200">&amp;#34;@google/genai&amp;#34;&lt;/span>&lt;span style="color:#111">;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00a8c8">const&lt;/span> &lt;span style="color:#75af00">ai&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#00a8c8">new&lt;/span> &lt;span style="color:#75af00">GoogleGenAI&lt;/span>&lt;span style="color:#111">({&lt;/span> &lt;span style="color:#75af00">apiKey&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#d88200">&amp;#34;YOUR_API_KEY&amp;#34;&lt;/span> &lt;span style="color:#111">});&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00a8c8">async&lt;/span> &lt;span style="color:#00a8c8">function&lt;/span> &lt;span style="color:#75af00">main&lt;/span>&lt;span style="color:#111">()&lt;/span> &lt;span style="color:#111">{&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#00a8c8">const&lt;/span> &lt;span style="color:#75af00">response&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#00a8c8">await&lt;/span> &lt;span style="color:#75af00">ai&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">models&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">generateContent&lt;/span>&lt;span style="color:#111">({&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75af00">model&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#d88200">&amp;#34;gemini-2.0-flash&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75af00">contents&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#d88200">&amp;#34;Explain how AI works in a few words&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#111">});&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75af00">console&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">log&lt;/span>&lt;span style="color:#111">(&lt;/span>&lt;span style="color:#75af00">response&lt;/span>&lt;span style="color:#111">.&lt;/span>&lt;span style="color:#75af00">text&lt;/span>&lt;span style="color:#111">);&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00a8c8">await&lt;/span> &lt;span style="color:#75af00">main&lt;/span>&lt;span style="color:#111">();&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>AI - Audio</title><link>https://HoshikawaRyuukou.github.io/posts/ai---audio/</link><pubDate>Wed, 07 May 2025 13:11:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---audio/</guid><description>&lt;h2 id="quick">Quick&lt;/h2>
&lt;p>這篇是不錯的導讀&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV17SVUznEGw">AI声音建模：MiniMax Audio 一键声音克隆&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>AI - Stable diffusion - Favorites</title><link>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---favorites/</link><pubDate>Fri, 02 May 2025 21:11:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---favorites/</guid><description>&lt;h2 id="quick-chat">Quick Chat&lt;/h2>
&lt;ul>
&lt;li>sd 1.5 系列基本上不使用了&lt;/li>
&lt;li>Illustrious 是目前的使用主力&lt;/li>
&lt;/ul>
&lt;h2 id="checkpoints">Checkpoints&lt;/h2>
&lt;p>底模基本分成兩種&lt;/p>
&lt;ul>
&lt;li>無風格模型 : lora 會很大程度影響出圖風格&lt;/li>
&lt;li>風格模型 : 模型本身有一定程度的風格，常用於抵消一些有瑕疵的 lora&lt;/li>
&lt;/ul>
&lt;h3 id="wai-nsfw-illustrious-sdxl">WAI-NSFW-illustrious-SDXL&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://civitai.com/models/827184?modelVersionId=1490781">link&lt;/a>&lt;/li>
&lt;li>無風格模型&lt;/li>
&lt;li>目前使用版本 12&lt;/li>
&lt;li>實測版本 13 效果似乎不如 12&lt;/li>
&lt;li>出圖速度較快，適合搭配優良 lora 使用&lt;/li>
&lt;/ul>
&lt;h3 id="steincustom">SteinCustom&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://civitai.com/models/1245022?modelVersionId=1669006">link&lt;/a>&lt;/li>
&lt;li>無風格模型，但能一定程度約束 lora 風格&lt;/li>
&lt;li>目前使用版本 6&lt;/li>
&lt;li>實測版本 7 風格有變得偏 pony 不太喜歡&lt;/li>
&lt;li>&lt;strong>年齡&lt;/strong> 控制相對有效 prompts (&lt;code>age up, meature female&lt;/code>)&lt;/li>
&lt;/ul>
&lt;h2 id="lora---styles">Lora - Styles&lt;/h2>
&lt;ul>
&lt;li>大部分的底模都有人物偏萌系/幼態的問題&lt;/li>
&lt;/ul>
&lt;h3 id="solo-leveling-anime-style">Solo Leveling Anime Style&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://civitai.com/models/1137411/solo-leveling-anime-style">link&lt;/a>&lt;/li>
&lt;li>增強 臉部銳利度&lt;/li>
&lt;li>增強 較長的體態&lt;/li>
&lt;li>增強 平塗效果&lt;/li>
&lt;li>⚠️頸部附近的 hard shadow 有時會過於明顯，需調控 prompts (&lt;code>anime coloring&lt;/code>) 權重&lt;/li>
&lt;/ul>
&lt;h3 id="violet-evergarden-anime-style">Violet Evergarden Anime Style&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://civitai.com/models/1334756/violet-evergarden-anime-style">link&lt;/a>&lt;/li>
&lt;li>增強 較小的眼睛&lt;/li>
&lt;li>增強 平塗效果&lt;/li>
&lt;/ul>
&lt;h2 id="prompts---artists">Prompts - Artists&lt;/h2>
&lt;ul>
&lt;li>權重超過 0.6 比較穩定(但有些太高會有點 overfitting)&lt;/li>
&lt;li>rella : 增加一些插畫風格&lt;/li>
&lt;/ul></description></item><item><title>AI - Firebase Studio</title><link>https://HoshikawaRyuukou.github.io/posts/ai---firebase-studio/</link><pubDate>Fri, 11 Apr 2025 08:11:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---firebase-studio/</guid><description>&lt;h2 id="quick-chat">Quick Chat&lt;/h2>
&lt;p>Firebase Studio 的前身是 Project IDX。&lt;/p>
&lt;p>Firebase Studio 是一個由 Google 提供的基於雲端的開發環境，旨在幫助開發者快速構建和發布全棧 AI 應用。這個平台結合了 AI 助手 Gemini 的功能，提供了一個集成的開發體驗，讓開發者能夠在一個地方完成應用的設計、開發和部署。&lt;/p>
&lt;p>目前，Firebase Studio 在預覽階段提供三個免費工作區，開發者可以在此期間無需付費使用該平台的功能。&lt;/p>
&lt;p>總的來說，看起來還輸 Cursor 一段距離，但追上應該是早晚的事。&lt;/p>
&lt;h2 id="guide">Guide&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV1K2d2YWEpW">💥谷歌免费发布Firebase Studio：AI应用开发神器，不试不行!&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>AI - Common - Note</title><link>https://HoshikawaRyuukou.github.io/posts/ai---common---note/</link><pubDate>Wed, 26 Mar 2025 13:11:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---common---note/</guid><description>&lt;h2 id="artificial-general-intelligenceagi">Artificial General Intelligence（AGI）&lt;/h2>
&lt;p>簡單來說，AGI（通用人工智慧）就像是一個能夠像人類一樣思考和學習的 AI。現在的 AI 通常只能做特定的事情，比如語音助理能聽懂指令、圖像辨識能認臉，但它們無法舉一反三或解決各種不同的問題。&lt;/p>
&lt;p>AGI 則不同，它能夠適應各種情境、學習新知識、自己思考並解決問題，就像一個真正有智慧的人。這也是人工智慧發展的終極目標——打造一個可以自由學習、理解世界的「超級 AI」。&lt;/p>
&lt;h2 id="edge-computing">Edge Computing&lt;/h2>
&lt;p>簡單來說，&lt;strong>邊緣運算&lt;/strong>就是讓資料的處理工作&lt;strong>盡量靠近資料來源&lt;/strong>，而不是全部送到遠端的伺服器（雲端）去計算。&lt;/p>
&lt;p>舉個例子，如果你在用自駕車，車子上的感測器會即時收集路況資訊。如果這些資料都要先傳到雲端再回來，可能會有延遲，影響安全。但如果車子本身就能&lt;strong>即時處理&lt;/strong>這些資料，那麼它可以&lt;strong>更快做出決策&lt;/strong>，避免危險。&lt;/p>
&lt;p>這種技術不只適合自駕車，也廣泛應用在&lt;strong>智慧工廠、AR/VR、智慧家庭&lt;/strong>等需要即時反應的領域，因為它可以&lt;strong>減少延遲、降低網路負擔，並提升運算效率&lt;/strong>。&lt;/p>
&lt;h2 id="retrieval-augmented-generationrag">Retrieval-Augmented Generation（RAG）&lt;/h2>
&lt;p>簡單來說，&lt;strong>RAG 就是讓 AI 會「先查資料再回答」&lt;/strong>，而不是單靠自己記住的知識來作答。&lt;/p>
&lt;p>一般的 AI 模型只能根據訓練時學到的內容回答問題，這可能會導致資訊過時或不夠準確。但 RAG 的特點是，它會&lt;strong>先去找最新或相關的資料&lt;/strong>，然後再根據這些資訊來產生回應。&lt;/p>
&lt;p>想像一下，你問 AI：「最近的 AI 技術發展如何？」一般的 AI 可能只會回答它訓練時學到的內容，但 RAG 會&lt;strong>先查找最新的研究或新聞&lt;/strong>，再提供更準確的答案。這讓它特別適合&lt;strong>問答系統、企業內部知識搜尋、技術支援&lt;/strong>等需要&lt;strong>即時、可靠資訊&lt;/strong>的應用。&lt;/p>
&lt;h2 id="multimodal">Multimodal&lt;/h2>
&lt;p>簡單來說，多模態 AI 就是讓人工智慧能夠同時理解和處理多種形式的資料，例如文字、圖片、聲音和影片等。​&lt;/p>
&lt;p>傳統的 AI 模型通常只專注於單一類型的資料，例如僅處理文字或圖像。​但多模態 AI 能夠整合不同形式的資訊，使其對世界的理解更加全面，並能執行更複雜的任務。&lt;/p>
&lt;h3 id="natively-multimodal原生多模態">Natively Multimodal（原生多模態）&lt;/h3>
&lt;p>所謂「原生」是指模型從一開始就是為多模態設計，並非後期再整合進去，因此能更自然、有效率地跨模態理解與生成資訊。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Gemini 2.0 Flash&lt;/strong>
&lt;ul>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=w0-L2kl_3cU">用嘴 P 圖的這一天真的來了！超強多模態 Gemini AI 讓一票設計師默默把繪圖板拿起來邊啃邊思考人生 ~&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>GPT 4o 原生多模態圖片生成&lt;/strong>
&lt;ul>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV1yZZMYEEQ4">OpenAI重大更新，降维打击，自然语言绘图功能修改图片功能跨代提升，真正的多模态，从此人人都是设计师&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="為圖像生成帶來更穩定可控的輸出">為圖像生成帶來更穩定/可控的輸出&lt;/h3>
&lt;ul>
&lt;li>角色一致性&lt;/li>
&lt;li>文字渲染能力&lt;/li>
&lt;li>支援多輪對話調整迭代創作(明確指示修改)&lt;/li>
&lt;li>基於參考圖二次創作(風格遷移)&lt;/li>
&lt;/ul>
&lt;h2 id="model-context-protocolmcp">Model Context Protocol（MCP）&lt;/h2>
&lt;p>模型上下文協議（Model Context Protocol，MCP）由 Anthropic 提出，是一種開放標準，用來規範 AI 模型與外部工具、資料來源的互動方式。&lt;/p></description></item><item><title>AI - Stable diffusion - Quick Start</title><link>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---quick-start/</link><pubDate>Mon, 17 Feb 2025 20:40:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---quick-start/</guid><description>&lt;h2 id="quick-chat">Quick Chat&lt;/h2>
&lt;ul>
&lt;li>⚠️ 這是一篇新手導向的筆記，目的不在於精準解釋。&lt;/li>
&lt;li>⚠️ 環境配置請參考 &lt;code>AI - Stable diffusion - Environment&lt;/code>&lt;/li>
&lt;li>⚠️ &lt;strong>Checkpoint&lt;/strong> 一般會提供推薦的參數設置，建議依據模型的特性調整，以獲得最佳效果。&lt;/li>
&lt;/ul>
&lt;h2 id="resources">Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://civitai.com/">Civitai: The Home of Open-Source Generative AI&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="checkpoint">Checkpoint&lt;/h2>
&lt;p>決定生成圖片的基礎風格。&lt;/p>
&lt;ul>
&lt;li>寫實風格 (Photorealistic)&lt;/li>
&lt;li>動漫風 (Anime)&lt;/li>
&lt;li>油畫風格 (Painting)&lt;/li>
&lt;li>科幻賽博龐克 (Cyberpunk)&lt;/li>
&lt;li>像素風格 (Pixel Art)&lt;/li>
&lt;/ul>
&lt;h2 id="lora">LoRA&lt;/h2>
&lt;p>輕量化微調模型可額外載入來增強特定風格或角色。&lt;/p>
&lt;ul>
&lt;li>簡單的比喻來形容 LoRA 模型，那就是「濾鏡」&lt;/li>
&lt;/ul>
&lt;h2 id="embedding">Embedding&lt;/h2>
&lt;p>增強對某些 Prompt 的理解。&lt;/p>
&lt;h2 id="vae">VAE&lt;/h2>
&lt;p>提高圖片細節與顏色準確度。&lt;/p>
&lt;ul>
&lt;li>📝 部分 Checkpoints 會內建（Baked）VAE，如使用外部 VAE，請確認是否需要覆蓋內建版本。&lt;/li>
&lt;li>⚠️ 如果發現圖片的型都對，但只有顏色壞掉，通常都是 VAE 的問題。&lt;/li>
&lt;/ul>
&lt;h2 id="sampler--schedule">Sampler + Schedule&lt;/h2>
&lt;p>Sampler 是從雜訊圖到成品的&lt;strong>去噪算法&lt;/strong>。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>快速收斂&lt;/strong> – 能迅速找到解答，適合驗證創意和想法。&lt;/li>
&lt;li>&lt;strong>高品質收斂&lt;/strong> – 需較長時間，但能提供更精確結果。&lt;/li>
&lt;li>&lt;strong>無固定收斂&lt;/strong> – 無明確收斂條件，為創新提供更大空間。&lt;/li>
&lt;/ul>
&lt;p>Schedule 是從雜訊圖到成品的&lt;strong>去噪程度&lt;/strong>。&lt;/p></description></item><item><title>AI - Stable diffusion - Extensions</title><link>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---extensions/</link><pubDate>Mon, 10 Feb 2025 22:16:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---extensions/</guid><description>&lt;h2 id="a1111-sd-webui-tagcomplete">a1111-sd-webui-tagcomplete&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/DominikDoom/a1111-sd-webui-tagcomplete">DominikDoom/a1111-sd-webui-tagcomplete&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="sd-webui-prompt-all-in-one">sd-webui-prompt-all-in-one&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Physton/sd-webui-prompt-all-in-one">Physton/sd-webui-prompt-all-in-one&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="adetailer">adetailer&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/Bing-su/adetailer">Bing-su/adetailer&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="sd-webui-photopea-embed">sd-webui-photopea-embed&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/yankooliveira/sd-webui-photopea-embed">yankooliveira/sd-webui-photopea-embed&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="sd-webui-lora-block-weight">sd-webui-lora-block-weight&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/hako-mikan/sd-webui-lora-block-weight">hako-mikan/sd-webui-lora-block-weight&lt;/a>&lt;/li>
&lt;li>XERSON005:1,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0&lt;/li>
&lt;li>PERSON105:1,0,0,1,1,0,0,0,1,1,1,0,0,0,0,0,0&lt;/li>
&lt;/ul></description></item><item><title>AI - Stable diffusion - GUI</title><link>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---gui/</link><pubDate>Mon, 10 Feb 2025 21:16:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---gui/</guid><description>&lt;h2 id="quick-chat">Quick Chat&lt;/h2>
&lt;p>建議新手直接從 Forge 入門即可&lt;/p>
&lt;h2 id="guide">Guide&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV1HDBZYBEjK">Comfyui官方客户端 desktop桌面版来了&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=bbuspQWHt9w">AI 繪圖的終極沙盒 ComfyUI 快速上手 #1 無視一切規則，AI 神級繪圖工具還給你全方位掌控權！&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=g3COb2joy1A">AI 繪圖的終極沙盒 ComfyUI 快速上手 #2 - LoRA 微調模型 &amp;amp; AI 影像畫質提升&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=rMlZ2Yaw3Ko">AI 繪圖的終極沙盒 ComfyUI 快速上手 #3 - ControlNet 精確構圖技巧&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="automatic1111">&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">Automatic1111&lt;/a>&lt;/h2>
&lt;p>是最早推出的圖形使用者介面之一，為使用者提供了直觀且功能豐富的操作平台。由於其開源性質和強大的社群支持，許多初學者和開發者選擇從 Automatic1111 入手，逐步熟悉 Stable Diffusion 的各項功能和應用。&lt;/p>
&lt;p>
 &lt;img src="https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/refs/heads/master/screenshot.png" alt="Automatic1111 Screenshot">

&lt;/p>
&lt;h2 id="forge">&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge">Forge&lt;/a>&lt;/h2>
&lt;p>基於 Automatic1111 進行了多項優化&lt;/p>
&lt;ul>
&lt;li>記憶體控制優化且推理速度提升&lt;/li>
&lt;li>算法優化&lt;/li>
&lt;li>新增取樣器&lt;/li>
&lt;li>簡化的命令標誌&lt;/li>
&lt;/ul>
&lt;p>介面與 Automatic1111 高度相似，基本能無痛從 Automatic1111 轉移。&lt;/p>
&lt;pre tabindex="0">&lt;code>set COMMANDLINE_ARGS=--xformers --no-half-vae --medvram
&lt;/code>&lt;/pre>&lt;h2 id="comfyui">&lt;a href="https://github.com/comfyanonymous/ComfyUI">ComfyUI&lt;/a>&lt;/h2>
&lt;p>是一個開源的節點式圖形介面，允許使用者通過直觀的節點系統設計和執行複雜的工作流程。&lt;/p>
&lt;p>
 &lt;img src="https://github.com/user-attachments/assets/7ccaf2c1-9b72-41ae-9a89-5688c94b7abe" alt="ComfyUI Screenshot">

&lt;/p></description></item><item><title>AI - Stable diffusion - Environment</title><link>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---environment/</link><pubDate>Mon, 10 Feb 2025 20:13:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---environment/</guid><description>&lt;h2 id="local-deployment">Local deployment&lt;/h2>
&lt;p>⚠️ 以下皆須安裝指定版本不可貿然升級&lt;/p>
&lt;ul>
&lt;li>nvidia 驅動更新至最新&lt;/li>
&lt;li>cuda: &lt;a href="https://developer.nvidia.com/cuda-12-1-0-download-archive">CUDA 12.1&lt;/a>
&lt;ul>
&lt;li>檢查顯卡支援的最高 cuda 支援: &lt;code>nvidia-smi&lt;/code>&lt;/li>
&lt;li>顯示CUDA編譯工具的版本信息: &lt;code>nvcc --version&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Python: &lt;a href="https://www.python.org/ftp/python/3.10.11/python-3.10.11-amd64.exe">Python 3.10.11&lt;/a>
&lt;ul>
&lt;li>&lt;code>python --version&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Git: &lt;a href="https://git-fork.com/">Fork&lt;/a>&lt;/li>
&lt;li>GUI: &lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge">lllyasviel/stable-diffusion-webui-forge&lt;/a>&lt;/li>
&lt;li>clone 上述專案，執行 &lt;code>webui.bat&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="google-colab">Google Colab&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/gutris1/segsmaker">gutris1/segsmaker&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/cagliostrolab/forge-colab">cagliostrolab/forge-colab&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="civitai-api-key">Civitai API Key&lt;/h2>
&lt;blockquote>
&lt;p>Menu &amp;gt; Account Settings(齒輪 icon) &amp;gt; API Keys&lt;/p>&lt;/blockquote></description></item><item><title>AI - Stable diffusion - Overview</title><link>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---overview/</link><pubDate>Thu, 06 Feb 2025 21:11:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---overview/</guid><description>&lt;h2 id="quick-chat">Quick Chat&lt;/h2>
&lt;p>建議閱讀順序&lt;/p>
&lt;ul>
&lt;li>AI - Stable diffusion - Environment&lt;/li>
&lt;li>AI - Stable diffusion - GUI&lt;/li>
&lt;li>AI - Stable diffusion - Quick Start&lt;/li>
&lt;li>AI - Stable diffusion - Extensions&lt;/li>
&lt;li>AI - Stable diffusion - CheckPoints&lt;/li>
&lt;li>AI - Stable diffusion - Resources&lt;/li>
&lt;/ul>
&lt;h2 id="core-working-principles">Core Working Principles&lt;/h2>
&lt;p>Stable Diffusion 主要包含三個核心技術：&lt;/p>
&lt;h3 id="前向擴散forward-diffusion">前向擴散（Forward Diffusion）&lt;/h3>
&lt;ul>
&lt;li>先從大量圖片資料集中學習圖片特徵。&lt;/li>
&lt;li>然後，系統會逐步加入高斯雜訊（Gaussian Noise），使圖片變得模糊、無法辨識。&lt;/li>
&lt;li>最後，這個過程會讓圖片變成完全的純雜訊（random noise）。&lt;/li>
&lt;/ul>
&lt;h3 id="反向去噪reverse-denoising--u-net">反向去噪（Reverse Denoising / U-Net）&lt;/h3>
&lt;ul>
&lt;li>Stable Diffusion 學習如何逆向去噪，一步步從雜訊還原出清晰的圖片。&lt;/li>
&lt;li>這部分的關鍵是 U-Net 神經網路架構，它可以在多層次的細節中，捕捉圖片的各種特徵。&lt;/li>
&lt;/ul>
&lt;h3 id="文本引導text-conditioning--clip">文本引導（Text Conditioning / CLIP）&lt;/h3>
&lt;ul>
&lt;li>Stable Diffusion 之所以能生成符合指令的圖片，是因為它使用了CLIP（Contrastive Language-Image Pretraining）。&lt;/li>
&lt;li>CLIP 會將文字轉換成向量表示（latent embeddings），這些向量再指導模型生成符合描述的圖像。&lt;/li>
&lt;/ul>
&lt;h3 id="diagram">Diagram&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://developer.nvidia.com/blog/improving-diffusion-models-as-an-alternative-to-gans-part-1/">Improving Diffusion Models as an Alternative To GANs, Part 1&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>
 &lt;img src="https://developer-blogs.nvidia.com/wp-content/uploads/2022/04/Generation-with-Diffusion-Models.png" alt="123">

&lt;/p></description></item><item><title>AI - Stable diffusion - Resources</title><link>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---resources/</link><pubDate>Wed, 05 Feb 2025 20:13:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---resources/</guid><description>&lt;h2 id="community">Community&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://civitai.com/">Civitai&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.qpipi.com/">Qpipi_AI绘画社区和SD模型&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="channel">Channel&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.hoshikou-ailabo.net/">星光のAIラボ&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://sorenuts.jp/">SoreNuts&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="prompts">Prompts&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://blog.256pages.com/sdxl-prompts-advanced-guide-1/">SDXL Prompts 進階指南 (1) - 鏡頭視角距離&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.256pages.com/stable-diffusion-prompt-distance/">Stable Diffusion 用 prompt 控制鏡頭距離及角度&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://civitai.com/articles/8804/illustrious-xl-noobai-xl-hairstyles">Illustrious XL / NoobAI XL Hairstyles&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="gallery">Gallery&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://pixai.art/">PixAI.Art&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aibooru.online/">AIBooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://civitai.com/user/Lizardon1025/images">Lizardon1025&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://civitai.com/user/pepegles/images">pepegles&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="artists">Artists&lt;/h2>
&lt;ul>
&lt;li>rella&lt;/li>
&lt;/ul>
&lt;hr>
&lt;ul>
&lt;li>&lt;a href="https://arca.live/b/aiart/73560719">artist list&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/artists">Artists | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?tags=akitetsu">Akitetsu | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?tags=sakamoto_masaru">Sakamoto Masaru | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?tags=fight_yoghurt">Fight Yoghurt | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?tags=reia_76">Reia 76 | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?page=1&amp;amp;tags=kagto_%28alterna%29">Kagto (Alterna) | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gelbooru.com/index.php?page=post&amp;amp;s=list&amp;amp;tags=mo_%28kireinamo%29">mo (kireinamo) | Gelbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?page=4&amp;amp;tags=happoubi_jin">Happoubi Jin | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?page=3&amp;amp;tags=ohisashiburi">Ohisashiburi | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?tags=shirotaka_%285choume%29">Shirotaka (5Choume) | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?tags=rokuwata_tomoe">Rokuwata Tomoe | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?tags=fight_yoghurt">Fight Yoghurt | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?tags=hidis0086">Hidis0086 | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?page=2&amp;amp;tags=ulrich_%28tagaragakuin%29">Ulrich (Tagaragakuin) | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?tags=haimura_kiyotaka">Haimura Kiyotaka | Danbooru&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;ul>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?tags=qtian">Qtian | Danbooru&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danbooru.donmai.us/posts?tags=zanya_000">Zanya 000 | Danbooru&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>AI - Stable diffusion - CheckPoints</title><link>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---checkpoints/</link><pubDate>Tue, 04 Feb 2025 21:11:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---stable-diffusion---checkpoints/</guid><description>&lt;h2 id="quick-chat">Quick Chat&lt;/h2>
&lt;ul>
&lt;li>⚠️ 以下主題專注於二次元/動漫風格圖像生成&lt;/li>
&lt;/ul>
&lt;h2 id="guide">Guide&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.pttweb.cc/bbs/C_Chat/M.1730732828.A.70C">Re: [問題] AI 風格怎麼了嗎？為什麼容易膩？ - 看板C_Chat - PTT網頁版&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="sd15">SD1.5&lt;/h2>
&lt;p>在性能和穩定性上提升很多，社群迎來爆發式成長。&lt;/p>
&lt;h3 id="milestoneevents">Milestone/Events&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Waifu Diffusion&lt;/strong>：這是一個基於 Stable Diffusion 的模型，專注於生成二次元風格的圖像。該模型使用 Danbooru 資料集進行訓練，適合生成各類動漫風格的圖像。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>NovelAI 模型外洩（NAI）&lt;/strong>：NovelAI 是一個提供 AI 輔助創作的服務平台，其專注於二次元圖像生成的模型曾發生外洩事件。該模型同樣使用 Danbooru 資料集進行訓練。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Anything 系列模型&lt;/strong>：Anything V3 和 V4 是專注於二次元圖像生成的模型，具有較高的生成質量和風格多樣性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>ChilloutMix&lt;/strong>：這是一個專注於生成寫實風格圖像的模型，能夠生成高品質的寫實人物圖像。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="resolutions">Resolutions&lt;/h3>
&lt;ul>
&lt;li>512 x 512 : 1:1&lt;/li>
&lt;li>512 X 768 : 2:3&lt;/li>
&lt;/ul>
&lt;h2 id="sdxl">SDXL&lt;/h2>
&lt;p>相比於 SD1.5 在多方面有顯著的提升&lt;/p>
&lt;ul>
&lt;li>&lt;strong>更大的模型規模&lt;/strong>：SDXL 的參數量遠超 SD1.5，這使其能夠捕捉更複雜的圖像特徵。&lt;/li>
&lt;li>&lt;strong>更高分辨率&lt;/strong>：SDXL 支持更高分辨率的圖像生成。&lt;/li>
&lt;li>&lt;strong>雙模型架構&lt;/strong>：SDXL 採用雙模型架構，包含一個基礎模型和一個精煉模型。基礎模型生成初步圖像，精煉模型進一步提升細節和質量，這種分工協作顯著提升了生成效果。&lt;/li>
&lt;li>&lt;strong>更強的文本理解能力&lt;/strong>：SDXL 在理解複雜提示詞方面表現更好，能更準確地將文本描述轉化為圖像內容，減少誤解和偏差。&lt;/li>
&lt;/ul>
&lt;h3 id="milestoneevents-1">Milestone/Events&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Pony Diffusion&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>訓練流程有使用審美分級標籤。&lt;/li>
&lt;li>原版 Pony 生成的結果接近歐美審美。&lt;/li>
&lt;li>Pony 系明顯缺點用色偏暗偏髒。&lt;/li>
&lt;li>Pony 在「多人互動」方面與 nsfw 表現很好。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>NovelAI 3 (NAI3)&lt;/strong>：&lt;/p></description></item><item><title>AI - Ollama - Google Colab + ngrok</title><link>https://HoshikawaRyuukou.github.io/posts/ai---ollama---google-colab-+-ngrok/</link><pubDate>Thu, 16 Jan 2025 21:11:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---ollama---google-colab-+-ngrok/</guid><description>&lt;h2 id="quick-chat">Quick Chat&lt;/h2>
&lt;p>參考以下教學&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=ZOCY61424JI">十分钟部署本地离线免费大模型！&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=JfI3K3HwQuI">Ngrok + Ollama | 在世界任何地方与localhost开源大模型聊天&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.gopenai.com/free-inference-is-all-i-need-how-to-run-large-language-models-for-free-using-google-colab-fe961e86503b">Free Inference Is All I Need: How to Run Large Language Models for Free Using Google Colab&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="requirements">Requirements&lt;/h2>
&lt;ul>
&lt;li>註冊 &lt;a href="https://ngrok.com/">ngrok&lt;/a> 帳號，取得 token ( ngrok &amp;gt; Your Authtoken )&lt;/li>
&lt;li>將 token 填至 colab &amp;gt; Secret
&lt;ul>
&lt;li>name : NGROK_AUTH&lt;/li>
&lt;li>value : token&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>本機端使用 &lt;a href="https://chromewebstore.google.com/detail/page-assist-a-web-ui-for/jfgfiigpkhlkbnfnbobbkinehhfdhndo">Page Assist - A Web UI for Local AI Models&lt;/a> 與 Ollama 互動&lt;/li>
&lt;/ul>
&lt;h2 id="steps">Steps&lt;/h2>
&lt;h3 id="安裝必要工具">安裝必要工具&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>!sudo apt-get install -y pciutils
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>!curl https://ollama.ai/install.sh &lt;span style="color:#111">|&lt;/span> sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>!pip install pyngrok
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;strong>安裝 pciutils&lt;/strong>: 提供硬件檢測和配置工具，用於檢查和診斷 GPU 設置。&lt;/li>
&lt;li>&lt;strong>安裝 Ollama&lt;/strong>: 下載並執行 Ollama 的安裝腳本。&lt;/li>
&lt;li>&lt;strong>安裝 pyngrok&lt;/strong>: 用於創建到本地服務的反向代理，從而將本地服務器公開到互聯網。&lt;/li>
&lt;/ul>
&lt;h3 id="啟動-ollama-服務器">啟動 Ollama 服務器&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-py" data-lang="py">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> &lt;span style="color:#111">os&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> &lt;span style="color:#111">threading&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> &lt;span style="color:#111">subprocess&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> &lt;span style="color:#111">requests&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> &lt;span style="color:#111">pyngrok&lt;/span> &lt;span style="color:#f92672">import&lt;/span> &lt;span style="color:#111">ngrok&lt;/span>&lt;span style="color:#111">,&lt;/span> &lt;span style="color:#111">conf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> &lt;span style="color:#111">google.colab&lt;/span> &lt;span style="color:#f92672">import&lt;/span> &lt;span style="color:#111">userdata&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00a8c8">def&lt;/span> &lt;span style="color:#75af00">ollama&lt;/span>&lt;span style="color:#111">():&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#111">os&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#111">environ&lt;/span>&lt;span style="color:#111">[&lt;/span>&lt;span style="color:#d88200">&amp;#39;OLLAMA_HOST&amp;#39;&lt;/span>&lt;span style="color:#111">]&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#d88200">&amp;#39;0.0.0.0:11434&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#111">os&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#111">environ&lt;/span>&lt;span style="color:#111">[&lt;/span>&lt;span style="color:#d88200">&amp;#39;OLLAMA_ORIGINS&amp;#39;&lt;/span>&lt;span style="color:#111">]&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#d88200">&amp;#39;*&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#111">os&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#111">environ&lt;/span>&lt;span style="color:#111">[&lt;/span>&lt;span style="color:#d88200">&amp;#39;OLLAMA_KEEP_ALIVE&amp;#39;&lt;/span>&lt;span style="color:#111">]&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#d88200">&amp;#39;-1&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#111">subprocess&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#111">Popen&lt;/span>&lt;span style="color:#111">([&lt;/span>&lt;span style="color:#d88200">&amp;#34;ollama&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span> &lt;span style="color:#d88200">&amp;#34;serve&amp;#34;&lt;/span>&lt;span style="color:#111">])&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">ollama_thread&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#111">threading&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#111">Thread&lt;/span>&lt;span style="color:#111">(&lt;/span>&lt;span style="color:#111">target&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#111">ollama&lt;/span>&lt;span style="color:#111">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">ollama_thread&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#111">start&lt;/span>&lt;span style="color:#111">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;strong>配置環境變量&lt;/strong>：
&lt;ul>
&lt;li>OLLAMA_HOST: 指定服務器的主機和端口，這裡為 0.0.0.0:11434，表示本地所有網絡接口。&lt;/li>
&lt;li>OLLAMA_ORIGINS: 設置跨域資源共享 (CORS) 的允許範圍。&lt;/li>
&lt;li>OLLAMA_KEEP_ALIVE: 保持服務器活躍的時長（-1 表示無限）。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>啟動 Ollama 服務器&lt;/strong>：使用 subprocess 啟動 Ollama 的服務模式。&lt;/li>
&lt;li>&lt;strong>使用執行緒運行服務器&lt;/strong>：確保主程序不被阻塞，允許服務器在後台運行。&lt;/li>
&lt;/ul>
&lt;h3 id="下載模型">下載模型&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://ollama.com/search">Ollama search&lt;/a>&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>!ollama pull &lt;span style="color:#f92672">{&lt;/span>model_name&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="公開服務">公開服務&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-py" data-lang="py">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">conf&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#111">get_default&lt;/span>&lt;span style="color:#111">()&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#111">auth_token&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#111">userdata&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#111">get&lt;/span>&lt;span style="color:#111">(&lt;/span>&lt;span style="color:#d88200">&amp;#39;NGROK_AUTH&amp;#39;&lt;/span>&lt;span style="color:#111">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">ollama_tunnel&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#111">ngrok&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#111">connect&lt;/span>&lt;span style="color:#111">(&lt;/span>&lt;span style="color:#d88200">&amp;#34;11434&amp;#34;&lt;/span>&lt;span style="color:#111">,&lt;/span> &lt;span style="color:#d88200">&amp;#34;http&amp;#34;&lt;/span>&lt;span style="color:#111">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">public_url&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#111">ollama_tunnel&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#111">public_url&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">print&lt;/span>&lt;span style="color:#111">(&lt;/span>&lt;span style="color:#d88200">f&lt;/span>&lt;span style="color:#d88200">&amp;#34;Public URL: &lt;/span>&lt;span style="color:#d88200">{&lt;/span>&lt;span style="color:#111">public_url&lt;/span>&lt;span style="color:#d88200">}&lt;/span>&lt;span style="color:#d88200">&amp;#34;&lt;/span>&lt;span style="color:#111">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;strong>配置 ngrok 驗證令牌&lt;/strong>：使用用戶提供的 NGROK_AUTH 確保 Tunnel 服務的授權。&lt;/li>
&lt;li>&lt;strong>創建 ngrok Tunnel&lt;/strong>： 將本地服務器（11434 端口）通過 HTTP 隧道公開到互聯網。&lt;/li>
&lt;li>&lt;strong>獲取公開 URL&lt;/strong>： 輸出 Tunnel 的公開 URL，便於遠程訪問 Ollama 服務。&lt;/li>
&lt;/ul>
&lt;h3 id="列出可用模型">列出可用模型&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>!ollama list
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="執行模型">執行模型&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>!ollama run &lt;span style="color:#f92672">{&lt;/span>model_name&lt;span style="color:#f92672">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="透過-page-assist-訪問">透過 Page Assist 訪問&lt;/h3>
&lt;ul>
&lt;li>於 Page Assist 設置 public_url&lt;/li>
&lt;li>訪問 public_url 並點擊 visit site，否則 Page Assist 偵測不到遠端 ollama&lt;/li>
&lt;/ul></description></item><item><title>AI - Prompt Engineering</title><link>https://HoshikawaRyuukou.github.io/posts/ai---prompt-engineering/</link><pubDate>Mon, 18 Nov 2024 21:11:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---prompt-engineering/</guid><description>&lt;h2 id="quick-chat">Quick Chat&lt;/h2>
&lt;p>提示工程是一種專注於設計和優化輸入提示的&lt;strong>操作者技術&lt;/strong>，旨在不改變模型的前提下，通過精心設計提示來提升生成式人工智慧（如大型語言模型，LLMs）的輸出品質。這種技術能幫助模型更準確地理解用戶意圖並生成符合需求的回應。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>提示（Prompt）&lt;/strong>：提示是提供給 AI 模型的輸入內容，如問題、命令或指示。高品質提示是生成高品質輸出的關鍵。&lt;/li>
&lt;/ul>
&lt;h2 id="guide">Guide&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://medium.com/@micky2428/%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B-prompt-engineering-%E5%A6%82%E4%BD%95%E6%9C%89%E6%95%88%E8%88%87ai%E5%B0%8D%E8%A9%B1-c4e6501c9bfd">提示工程(Prompt Engineering)：如何有效與AI對話&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="practice---github-copilot">Practice - Github Copilot&lt;/h2>
&lt;h3 id="domain-model">Domain Model&lt;/h3>
&lt;ul>
&lt;li>偏重邏輯，提示詞規格越詳細越好。&lt;/li>
&lt;/ul>
&lt;h3 id="vue-component">Vue Component&lt;/h3>
&lt;ul>
&lt;li>前端組件，初期提示詞規格未必越詳細越好。&lt;/li>
&lt;li>建議先實現核心功能，再逐步優化。&lt;/li>
&lt;li>中後期規格大幅調整，修改成功率偏低(尤其是&lt;strong>布局相關&lt;/strong>失敗率較高)。&lt;/li>
&lt;li>提供範例檔案有助於生成，例如：&lt;code>基於 XXX.vue 幫我寫另一個 OOO.vue 的組件&lt;/code>。&lt;/li>
&lt;/ul>
&lt;h3 id="extras">Extras&lt;/h3>
&lt;ul>
&lt;li>原型階段不建議過早拆分以免降低開發效率。&lt;/li>
&lt;li>基本成形後可封裝部分可以考慮重構為小單元，提升處理效率(減少重複生成相同部位)。&lt;/li>
&lt;li>雖然可透過 selection 的方式局部修正，但目前讓完整上下文一起參與生成較為穩健。&lt;/li>
&lt;/ul></description></item><item><title>AI - Note</title><link>https://HoshikawaRyuukou.github.io/posts/ai---note/</link><pubDate>Thu, 29 Aug 2024 13:11:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---note/</guid><description>&lt;h2 id="guide">Guide&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=eraWvfD_Ihg">一小時略懂 AI｜GPT、Sora、Diffusion model、類器官智慧OI、圖靈測試、人工智慧史&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=jW2cmZ-9hLk">【人工智能】模型压缩四大方法概述 | 量化、剪枝、蒸馏和二值化 | 模型瘦身 | 降低精度 | 速度提升 | 知识蒸馏 | 温度参数 | XNOR | 优缺点 | 发展方向&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.bilibili.com/video/BV1z8XpYKEnr">Gemini逆袭Controlnet？扩散模型和自回归模型的真正秘密&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="news">News&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.aibase.com/zh/">AIbase基地 - 让更多人看到未来 通往AGI之路&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="coding">Coding&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=IqVo8V4QNm0">GitHub项目理解神器：DeepWiki&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/AsyncFuncAI/deepwiki-open">AsyncFuncAI/deepwiki-open&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="translation">Translation&lt;/h2>
&lt;ul>
&lt;li>GPT Translator&lt;/li>
&lt;li>&lt;a href="https://github.com/SakuraLLM/SakuraLLM">SakuraLLM/SakuraLLM&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/zyddnys/manga-image-translator">zyddnys/manga-image-translator&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/dmMaze/BallonsTranslator">dmMaze/BallonsTranslator&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="vedio">Vedio&lt;/h2>
&lt;ul>
&lt;li>Veo 2&lt;/li>
&lt;/ul></description></item><item><title>AI - Ollama - Note</title><link>https://HoshikawaRyuukou.github.io/posts/ai---ollama---note/</link><pubDate>Mon, 19 Aug 2024 21:11:00 +0000</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---ollama---note/</guid><description>&lt;h2 id="guide">Guide&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://ollama.com/">Ollama&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="ui">UI&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://chromewebstore.google.com/detail/page-assist-a-web-ui-for/jfgfiigpkhlkbnfnbobbkinehhfdhndo">Page Assist - A Web UI for Local AI Models&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="commands">Commands&lt;/h2>
&lt;ul>
&lt;li>ollama list : 查看以配置本地模型&lt;/li>
&lt;li>ollama run {model} : 下載/執行模型&lt;/li>
&lt;li>ollama ps : 展示目前載入的模型、它們所佔的記憶體大小以及所使用的處理器類型（GPU 或 CPU）&lt;/li>
&lt;/ul>
&lt;h2 id="use-model-from-ollama">Use model from Ollama&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://ollama.com/search">Ollama search&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="use-gguf-model-from-hugging-face-hub">Use GGUF model from Hugging Face Hub&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Run Ollama with specified model&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># ollama run hf.co/{username}/{repository}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Run Ollama with specified model and desired quantization&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># ollama run hf.co/{username}/{repository}:{quantization}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:IQ3_M
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="use-gguf-model-from-local">Use GGUF model from local&lt;/h2>
&lt;h3 id="import_gguf_to_ollamabat">import_gguf_to_ollama.bat&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bat" data-lang="bat">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">@&lt;/span>&lt;span style="color:#00a8c8">echo&lt;/span> off
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">REM 設定本地環境，並切換到批次檔所在的目錄&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00a8c8">setlocal&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00a8c8">cd&lt;/span> /d &lt;span style="color:#111">%~dp0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">REM 搜尋當前目錄中的 .gguf 檔案&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00a8c8">for&lt;/span> &lt;span style="color:#8045ff">%%&lt;/span>f &lt;span style="color:#00a8c8">in&lt;/span> &lt;span style="color:#111">(&lt;/span>*.gguf&lt;span style="color:#111">)&lt;/span> &lt;span style="color:#00a8c8">do&lt;/span> &lt;span style="color:#111">(&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">REM 創建 Modelfile.txt 並寫入模型檔案名稱&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#00a8c8">echo&lt;/span> FROM &lt;span style="color:#8045ff">%%&lt;/span>~nf.gguf &lt;span style="color:#111">&amp;gt;&lt;/span> Modelfile.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">REM 打印 Modelfile.txt 的內容以供確認&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#00a8c8">type&lt;/span> Modelfile.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">REM 執行 ollama create 命令來包裝模型檔&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ollama create &lt;span style="color:#8045ff">%%&lt;/span>~nf -f Modelfile.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">REM 刪除 Modelfile.txt&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#00a8c8">del&lt;/span> Modelfile.txt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">REM 如果有多個 gguf 檔案，只處理第一個找到的檔案&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#00a8c8">goto&lt;/span> &lt;span style="color:#111">end&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#111">:&lt;/span>&lt;span style="color:#111">end&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">REM 顯示完成訊息&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00a8c8">echo&lt;/span> done...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">REM 列出已經存在的模型&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ollama list 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">REM 等待用戶確認並關閉&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00a8c8">pause&lt;/span> &lt;span style="color:#111">&amp;gt;&lt;/span>nul
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item></channel></rss>