<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on 識之箱庭</title><link>https://HoshikawaRyuukou.github.io/tags/ai/</link><description>Recent content in AI on 識之箱庭</description><generator>Hugo</generator><language>zh-tw</language><copyright>HoshikawaRyuukou</copyright><lastBuildDate>Fri, 17 Oct 2025 14:12:33 +0800</lastBuildDate><atom:link href="https://HoshikawaRyuukou.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>AI - Coding - SDD - OpenSpec</title><link>https://HoshikawaRyuukou.github.io/posts/ai-coding---sdd---openspec/</link><pubDate>Fri, 17 Oct 2025 14:12:33 +0800</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai-coding---sdd---openspec/</guid><description>&lt;h2 id="quick-chat"&gt;Quick Chat&lt;/h2&gt;
&lt;p&gt;在使用 OpenSpec 進行開發的體驗相當不錯，我認為原作者的設計理念解決了許多團隊在導入 AI 協作時的痛點。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;OpenSpec 的核心優勢：&lt;/strong&gt; 它極其擅長管理&lt;strong&gt;既有功能的變更 (1→n)&lt;/strong&gt;。 OpenSpec 是一個&lt;strong&gt;輕量級&lt;/strong&gt;的框架，無需 API 金鑰即可輕鬆整合到現有專案中，不需從頭來過。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;現有工具的痛點：&lt;/strong&gt; 許多工具如 &lt;code&gt;spec-kit&lt;/code&gt; 或 &lt;code&gt;Kiro&lt;/code&gt; 在處理&lt;strong&gt;從零到一 (0→1) 的全新專案&lt;/strong&gt;時表現非常出色。 然而，當專案進入維護與迭代階段，需要持續更新和管理不斷演進的「規格文件」時，這些工具就顯得力不從心。它們的結構在追蹤「系統當前狀態」以及「即將發生的變更」時，往往不夠直觀。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;清晰的檔案結構：&lt;/strong&gt; OpenSpec 透過簡單的雙資料夾結構，讓規格與變更的管理一目了然，有效地將「事實的根源」與「進行中的提案」分開：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;specs/&lt;/code&gt; → &lt;strong&gt;系統的當前狀態&lt;/strong&gt;：存放目前系統的規格，是團隊與 AI 的共同認知基礎。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;changes/&lt;/code&gt; → &lt;strong&gt;進行中的變更&lt;/strong&gt;：所有新的功能需求或修改都會在這裡以獨立的資料夾進行，包含提案、任務列表與規格草案。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;archive/&lt;/code&gt; → &lt;strong&gt;已完成的變更歷史&lt;/strong&gt;：所有已合併的變更都會被移至此處，成為一份「活文件」，記錄系統的演進歷程。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="guide"&gt;Guide&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/Fission-AI/OpenSpec"&gt;GitHub - Fission-AI/OpenSpec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ANjiJQQIBo0"&gt;開發者福音！用 AI 迭代現有專案？OpenSpec 讓 AI 按規範寫程式碼，零失誤！&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一位開發者的使用心得分享，原作者也在評論區參與了討論，提供了更多有趣的見解。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=cQv3ocbsKHY"&gt;I Found the Simplest AI Dev Tool Ever&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="workflow"&gt;Workflow&lt;/h2&gt;
&lt;p&gt;這個流程確保了人類開發者與 AI 之間能夠進行順暢且可控的協作，在 AI 動手寫程式碼&lt;strong&gt;之前&lt;/strong&gt;，就先對齊目標。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;起草變更提案 (Draft Change Proposal)：&lt;/strong&gt; 開發者向 AI 提出一個新的功能需求或變更請求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;審查與對齊 (Review &amp;amp; Align)：&lt;/strong&gt; AI 會根據你的請求生成詳細的規格與任務列表。開發者此時可以審查、提出修改意見，AI 會再根據回饋更新，形成一個&lt;strong&gt;反覆回饋的循環&lt;/strong&gt;，直到雙方對「要做什麼」與「如何做」達成共識。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;執行任務 (Implement Tasks)：&lt;/strong&gt; AI 依據最終拍板定案的規格與任務列表，開始進行程式碼的編寫。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;套用變更 (Apply the Change)：&lt;/strong&gt; 開發者審查 AI 生成的程式碼，確認無誤後，執行指令將程式碼合併到專案中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;封存與更新 (Archive &amp;amp; Update Specs)：&lt;/strong&gt; 變更完成後，該次的變更紀錄會被完整地「封存」到 &lt;code&gt;archive/&lt;/code&gt; 資料夾，同時更新 &lt;code&gt;specs/&lt;/code&gt; 中的主要規格文件，確保規格文件永遠處於最新狀態，為下一次的變更做好準備。&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>Gemini - Google AI Studio</title><link>https://HoshikawaRyuukou.github.io/posts/gemini---google-ai-studio/</link><pubDate>Wed, 15 Oct 2025 15:17:27 +0800</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/gemini---google-ai-studio/</guid><description>&lt;h2 id="quick-chat"&gt;Quick Chat&lt;/h2&gt;
&lt;p&gt;Google AI Studio 是 Google 推出的線上平台，主要定位在協助開發者、學生與研究人員快速試用 &lt;strong&gt;Gemini 模型&lt;/strong&gt;，並透過 &lt;strong&gt;Gemini Developer API&lt;/strong&gt; 來建立原型或應用程式。&lt;/p&gt;
&lt;p&gt;與一般的 Gemini 應用（像 ChatGPT 類型的介面）相比，AI Studio 提供了更多的 &lt;strong&gt;免費額度&lt;/strong&gt;，對想要動手實驗 Gemini 功能的人來說相當友善。&lt;/p&gt;
&lt;h2 id="guide"&gt;Guide&lt;/h2&gt;
&lt;h3 id="chat"&gt;Chat&lt;/h3&gt;
&lt;p&gt;常用的控制項包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Grounding with Google Search&lt;/strong&gt;：可在回答前透過 Google 搜尋補強資訊，使回覆更準確。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;URL context&lt;/strong&gt;：可將指定連結內容作為上下文，讓回答更貼近指定網頁的資訊。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="build"&gt;Build&lt;/h3&gt;
&lt;p&gt;這個區域能將「文字提示」轉化為可執行的 Web 應用程式。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Vibe Coding&lt;/strong&gt; 功能在開發簡單原型或概念驗證（PoC）時相當好用。&lt;/li&gt;
&lt;li&gt;不過在進行功能迭代時，有時會導致整個結構被重新生成 😂。&lt;/li&gt;
&lt;li&gt;若只是開發「自用型」應用程式（不綁 API Key），頂多遇到免費流量上限就無法繼續使用；&lt;/li&gt;
&lt;li&gt;若要分享或部署給他人，則需要考慮 &lt;strong&gt;API 使用費用&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前開發了幾個小應用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gemini 圖片翻譯器：使用 Gemini 翻譯圖片而不是 Google Translate。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="notice"&gt;Notice&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;若開啟歷史紀錄功能，AI Studio 的紀錄會自動儲存在 &lt;strong&gt;Google Drive&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;由於目前平台 &lt;strong&gt;未提供批次刪除功能&lt;/strong&gt;，若想清空紀錄，必須手動至 Google Drive 操作。&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>AI - Prompt - Headshot</title><link>https://HoshikawaRyuukou.github.io/posts/ai---prompt---headshot/</link><pubDate>Sat, 27 Sep 2025 13:55:55 +0800</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---prompt---headshot/</guid><description>&lt;h2 id="quick-chat"&gt;Quick Chat&lt;/h2&gt;
&lt;p&gt;最近為了更新履歷需要一張專業大頭照，但我手邊只有生活照。於是我使用 Google AI Studio 上的 &lt;strong&gt;Gemini 2.5 Flash Image (Nano Banana)&lt;/strong&gt;，效果相當不錯。&lt;/p&gt;
&lt;h2 id="practice"&gt;Practice&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;服裝&lt;/strong&gt;：深色西裝 &lt;br&gt;
&lt;strong&gt;光線&lt;/strong&gt;：側光，額頭去除油光 &lt;br&gt;
&lt;strong&gt;構圖&lt;/strong&gt;：半身照，臉部佔 70%~80% &lt;br&gt;
&lt;strong&gt;尺寸&lt;/strong&gt;：4.5 公分 × 3.5 公分 &lt;br&gt;
&lt;strong&gt;表情&lt;/strong&gt;：微笑但自然，嘴巴合閉不露齒 &lt;br&gt;
&lt;strong&gt;背景&lt;/strong&gt;：白色，光源均勻，無陰影或反光 &lt;br&gt;
&lt;strong&gt;品質&lt;/strong&gt;：清晰對焦，高品質無摺痕 &lt;br&gt;
&lt;strong&gt;角度&lt;/strong&gt;：眼睛正視鏡頭&lt;/p&gt;
&lt;p&gt;⚠️ 關於&lt;strong&gt;尺寸&lt;/strong&gt;的指令（如 4.5cm × 3.5cm），目前的 AI 模型通常無法直接生成精確的實體尺寸。 加入這項指令主要是為了讓 AI 更理解「這是一張證件照」的脈絡，從而優化構圖與臉部比例。最終，你仍需要將生成圖片匯入影像編輯軟體進行手動裁切，以符合最終需求。&lt;/p&gt;</description></item><item><title>AI - Agent - Gemini CLI - Custom Slash Command</title><link>https://HoshikawaRyuukou.github.io/posts/ai---agent---gemini-cli---custom-slash-command/</link><pubDate>Sun, 14 Sep 2025 14:04:32 +0800</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---agent---gemini-cli---custom-slash-command/</guid><description>&lt;h2 id="quick-chat"&gt;Quick Chat&lt;/h2&gt;
&lt;p&gt;Gemini CLI 已經成了我的主力工具。那些常用的操作，我乾脆全都包成 &lt;strong&gt;custom slash commands&lt;/strong&gt;，用起來順手又舒服。&lt;/p&gt;
&lt;p&gt;它的體驗和寫 Bash 腳本完全不同——這裡是透過自然語言跟 AI 對話，還能搭配 Gemini 的多模態功能，玩起來別有一番風味。當然，若單比執行效率，傳統腳本命令可能還是更勝一籌。&lt;/p&gt;
&lt;p&gt;印象最深的一次，是一個簡單的編輯搬移任務，結果來回居然跑了 &lt;strong&gt;30 個 requests&lt;/strong&gt; 才完成……&lt;/p&gt;
&lt;h2 id="guide"&gt;Guide&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cloud.google.com/blog/topics/developers-practitioners/gemini-cli-custom-slash-commands"&gt;Gemini CLI: Custom slash commands | Google Cloud Blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/google-cloud/gemini-cli-tutorial-series-part-7-custom-slash-commands-64c06195294b"&gt;Gemini CLI Tutorial Series — Part 7 : Custom slash commands&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="samples"&gt;Samples&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/amitkmaraj/gemini-cli-custom-slash-commands"&gt;GitHub - amitkmaraj/gemini-cli-custom-slash-commands: Some great custom slash commands to supercharge your workflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>AI - Favorites</title><link>https://HoshikawaRyuukou.github.io/posts/ai---favorites/</link><pubDate>Fri, 05 Sep 2025 10:25:42 +0800</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---favorites/</guid><description>&lt;h2 id="quick-chat"&gt;Quick Chat&lt;/h2&gt;
&lt;p&gt;記錄些目前使用率很高的 AI 工具 🤓。&lt;/p&gt;
&lt;h2 id="collections"&gt;Collections&lt;/h2&gt;
&lt;h3 id="chat"&gt;Chat&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://aistudio.google.com/prompts/new_chat"&gt;Google AI Studio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chatgpt.com/"&gt;ChatGPT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gemini.google.com/app?hl=zh-TW"&gt;Google Gemini&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://grok.com/"&gt;Grok&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="search"&gt;Search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://felo.ai/zh-Hant/search"&gt;Felo - 您的免費 AI 搜尋引擎&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="all-in-one"&gt;All-in-One&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.genspark.ai/"&gt;Genspark - 一站式 AI 工作空間&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="design"&gt;Design&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.lovart.ai/zh-TW"&gt;Lovart | 全球首個設計智能體&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=XtWHGmEz5CA"&gt;🔥Google Stitch颠覆传统UI设计！10秒生成专业级UI！快速生成产品原型！小白也能开发精美UI。 支持无缝导入Figma！ Stitch保姆级教程：从想法到APP大师级界面效果堪比专业团队 - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>AI - Tools</title><link>https://HoshikawaRyuukou.github.io/posts/ai---tools/</link><pubDate>Fri, 29 Aug 2025 10:08:39 +0800</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---tools/</guid><description>&lt;h2 id="news"&gt;News&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.aibase.com/zh/"&gt;AIbase基地 - 让更多人看到未来 通往AGI之路&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="audio"&gt;Audio&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.bilibili.com/video/BV17SVUznEGw"&gt;AI声音建模：MiniMax Audio 一键声音克隆&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="coding"&gt;Coding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=IqVo8V4QNm0"&gt;GitHub项目理解神器：DeepWiki&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/AsyncFuncAI/deepwiki-open"&gt;AsyncFuncAI/deepwiki-open&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="design"&gt;Design&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=c0K308mLz8U"&gt;【Lovart】設計師偷偷在用的AI 工具🫢 3分鐘搞定 Logo＋海報＋網站🔥 Laichu - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="translation"&gt;Translation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/SakuraLLM/SakuraLLM"&gt;SakuraLLM/SakuraLLM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/zyddnys/manga-image-translator"&gt;zyddnys/manga-image-translator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dmMaze/BallonsTranslator"&gt;dmMaze/BallonsTranslator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Stable Diffusion - Inpainting</title><link>https://HoshikawaRyuukou.github.io/posts/stable-diffusion---inpainting/</link><pubDate>Thu, 12 Jun 2025 10:00:00 +0800</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/stable-diffusion---inpainting/</guid><description>&lt;h2 id="quick-chat"&gt;Quick Chat&lt;/h2&gt;
&lt;p&gt;目前並未特別使用進階修圖技巧。若圖片瑕疵可透過簡單塗色與描邊處理，即會嘗試修復。&lt;/p&gt;
&lt;p&gt;若瑕疵較嚴重，則多半直接放棄並重新生成 —— 通常下一張會更好。&lt;/p&gt;
&lt;h2 id="modification"&gt;Modification&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;圖片先送入 &lt;code&gt;img2img&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;簡單處理：使用 &lt;code&gt;Inpaint sketch&lt;/code&gt;（注意不要在 sketch 模式下直接生成）。&lt;/li&gt;
&lt;li&gt;複雜處理：使用 &lt;code&gt;photopea-embed&lt;/code&gt; 進行手動遮罩或編輯。&lt;/li&gt;
&lt;li&gt;完成後再送回 &lt;code&gt;Inpaint&lt;/code&gt; 重新生成。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="generation"&gt;Generation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;採樣方法（Sampling method）：&lt;code&gt;DPM++ 2M&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;時間表類型（Schedule type）：&lt;code&gt;Karras&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;去雜強度（Denoising strength）建議範圍：
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;0.2 ~ 0.3&lt;/code&gt;：保留原圖整體色彩結構，僅微調瑕疵與過渡區域。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;0.3 ~ 0.5&lt;/code&gt;：適度改變結構與細節，適合嘗試新的構圖或調整 seed 取得更好結果。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>AI - Common</title><link>https://HoshikawaRyuukou.github.io/posts/ai---common/</link><pubDate>Wed, 26 Mar 2025 10:08:39 +0800</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/ai---common/</guid><description>&lt;h2 id="quick-chat"&gt;Quick Chat&lt;/h2&gt;
&lt;p&gt;近幾年 AI 發展一日千里。😅&lt;/p&gt;
&lt;h2 id="guide"&gt;Guide&lt;/h2&gt;
&lt;h3 id="artificial-general-intelligenceagi"&gt;Artificial General Intelligence（AGI）&lt;/h3&gt;
&lt;p&gt;AGI 就像能像人類一樣思考和學習的 AI。與目前只能處理特定任務的 AI 不同，AGI 能適應各種情境、學習新知、獨立思考並解決問題，是人工智慧的終極目標。&lt;/p&gt;
&lt;h3 id="edge-computing"&gt;Edge Computing&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;邊緣運算&lt;/strong&gt;就是讓資料在&lt;strong&gt;靠近來源端&lt;/strong&gt;的地方處理，而非全部送往遠端伺服器（雲端）計算。例如，自駕車能即時處理感測器資料，&lt;strong&gt;更快做出決策&lt;/strong&gt;，減少延遲並提升效率。此技術廣泛應用於&lt;strong&gt;自駕車、智慧工廠、AR/VR、智慧家庭&lt;/strong&gt;等需要即時反應的領域。&lt;/p&gt;
&lt;h3 id="retrieval-augmented-generationrag"&gt;Retrieval-Augmented Generation（RAG）&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;RAG 就是讓 AI「先查資料再回答」&lt;/strong&gt;，不單靠自身記憶。傳統 AI 模型可能因資訊過時而回答不準確，RAG 則會&lt;strong&gt;先查找最新資料&lt;/strong&gt;後再生成回應。這讓它特別適合&lt;strong&gt;問答系統、知識搜尋、技術支援&lt;/strong&gt;等需要&lt;strong&gt;即時可靠資訊&lt;/strong&gt;的應用。&lt;/p&gt;
&lt;h3 id="multimodal"&gt;Multimodal&lt;/h3&gt;
&lt;p&gt;多模態 AI 能同時理解和處理多種資料，如文字、圖片、聲音和影片。相較於只專注單一資料的傳統 AI，多模態 AI 能整合不同資訊，對世界的理解更全面，並執行更複雜的任務。&lt;/p&gt;
&lt;h3 id="natively-multimodal"&gt;Natively Multimodal&lt;/h3&gt;
&lt;p&gt;「原生多模態」是指模型從設計之初就支援多模態，因此能更自然、高效地跨模態理解與生成資訊。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Gemini 2.0 Flash&lt;/strong&gt;   - &lt;a href="https://www.youtube.com/watch?v=w0-L2kl_3cU"&gt;用嘴 P 圖的這一天真的來了！超強多模態 Gemini AI 讓一票設計師默默把繪圖板拿起來邊啃邊思考人生 ~&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GPT 4o 原生多模態圖片生成&lt;/strong&gt;   - &lt;a href="https://www.bilibili.com/video/BV1yZZMYEEQ4"&gt;OpenAI重大更新，降维打击，自然语言绘图功能修改图片功能跨代提升，真正的多模态，从此人人都是设计师&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="model-context-protocolmcp"&gt;Model Context Protocol（MCP）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.bilibili.com/video/BV1XFhPzoEBx"&gt;Function Calling、MCP和A2A的核心原理与区别&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;模型上下文協議（MCP）由 Anthropic 提出，是一種規範 AI 模型與外部工具、資料互動的開放標準。它像 AI 的「萬用轉接頭」，透過統一規範，讓 AI 無縫存取 API、資料庫與應用程式，大幅提升開發效率與彈性。&lt;/p&gt;
&lt;h2 id="extras"&gt;Extras&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=eraWvfD_Ihg"&gt;一小時略懂 AI｜GPT、Sora、Diffusion model、類器官智慧OI、圖靈測試、人工智慧史&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=jW2cmZ-9hLk"&gt;【人工智能】模型压缩四大方法概述 | 量化、剪枝、蒸馏和二值化 | 模型瘦身 | 降低精度 | 速度提升 | 知识蒸馏 | 温度参数 | XNOR | 优缺点 | 发展方向&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.bilibili.com/video/BV1z8XpYKEnr"&gt;Gemini逆袭Controlnet？扩散模型和自回归模型的真正秘密&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ZLDfTwHm56A"&gt;AI思维链是幻象吗？[白话读论文] - YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Stable Diffusion - Quick Start</title><link>https://HoshikawaRyuukou.github.io/posts/stable-diffusion---quick-start/</link><pubDate>Mon, 17 Feb 2025 10:00:00 +0800</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/stable-diffusion---quick-start/</guid><description>&lt;h2 id="quick-chat"&gt;Quick Chat&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;⚠️ 這是一篇新手導引，目的不在於精準解釋。&lt;/li&gt;
&lt;li&gt;⚠️ &lt;strong&gt;Checkpoint&lt;/strong&gt; 一般會提供推薦的參數設置，建議依據模型的特性調整，以獲得最佳效果。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="resources"&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://civitai.com/"&gt;Civitai: The Home of Open-Source Generative AI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="checkpoint"&gt;Checkpoint&lt;/h2&gt;
&lt;p&gt;決定生成圖片的基礎風格。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;寫實風格 (Photorealistic)&lt;/li&gt;
&lt;li&gt;動漫風 (Anime)&lt;/li&gt;
&lt;li&gt;油畫風格 (Painting)&lt;/li&gt;
&lt;li&gt;科幻賽博龐克 (Cyberpunk)&lt;/li&gt;
&lt;li&gt;像素風格 (Pixel Art)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="lora"&gt;LoRA&lt;/h2&gt;
&lt;p&gt;輕量化微調模型可額外載入來增強特定風格或角色。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;簡單的比喻來形容 LoRA 模型，那就是「濾鏡」&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="embedding"&gt;Embedding&lt;/h2&gt;
&lt;p&gt;增強對某些 Prompt 的理解。&lt;/p&gt;
&lt;h2 id="vae"&gt;VAE&lt;/h2&gt;
&lt;p&gt;提高圖片細節與顏色準確度。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;📝 部分 Checkpoints 會內建（Baked）VAE，如使用外部 VAE，請確認是否需要覆蓋內建版本。&lt;/li&gt;
&lt;li&gt;⚠️ 如果發現圖片的型都對，但只有顏色壞掉，通常都是 VAE 的問題。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="resolutions"&gt;Resolutions&lt;/h2&gt;
&lt;p&gt;不同種類的 Checkpoints 建議的解析度會有所不同&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SD 1.5
&lt;ul&gt;
&lt;li&gt;512 x 512 : 1:1&lt;/li&gt;
&lt;li&gt;512 X 768 : 2:3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SDXL
&lt;ul&gt;
&lt;li&gt;640 x 1536 = 5:12&lt;/li&gt;
&lt;li&gt;768 x 1344 = 4:7&lt;/li&gt;
&lt;li&gt;832 x 1216 = 13:19&lt;/li&gt;
&lt;li&gt;896 x 1152 = 7:9&lt;/li&gt;
&lt;li&gt;1024 x 1024 = 1:1&lt;/li&gt;
&lt;li&gt;1024 x 1536 = 2:3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="sampler--schedule"&gt;Sampler + Schedule&lt;/h2&gt;
&lt;p&gt;Sampler 是從雜訊圖到成品的&lt;strong&gt;去噪算法&lt;/strong&gt;。&lt;/p&gt;</description></item><item><title>Stable Diffusion - Env</title><link>https://HoshikawaRyuukou.github.io/posts/stable-diffusion---env/</link><pubDate>Mon, 10 Feb 2025 10:00:00 +0800</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/stable-diffusion---env/</guid><description>&lt;h2 id="quick-chat"&gt;Quick Chat&lt;/h2&gt;
&lt;p&gt;⚠️ 以下皆須安裝指定版本不可貿然升級。&lt;/p&gt;
&lt;p&gt;目前產圖只使用到 Forge + SDXL 。&lt;/p&gt;
&lt;h2 id="local-deployment"&gt;Local deployment&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;nvidia 驅動更新至最新&lt;/li&gt;
&lt;li&gt;檢查顯卡支援的最高 cuda 支援: &lt;code&gt;nvidia-smi&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;安裝 &lt;a href="https://developer.nvidia.com/cuda-12-1-0-download-archive"&gt;CUDA 12.1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;顯示 cuda 編譯工具的版本信息: &lt;code&gt;nvcc --version&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;安裝 [&lt;a href="https://github.com/lllyasviel/stable-diffusion-webui-forge"&gt;stable-diffusion-webui-forge&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="google-colab"&gt;Google Colab&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/gutris1/segsmaker"&gt;gutris1/segsmaker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;配置 Civitai API Key
&lt;ul&gt;
&lt;li&gt;Civitai 網站 Menu &amp;gt; Account Settings(齒輪 icon) &amp;gt; API Keys&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="extensions"&gt;Extensions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/DominikDoom/a1111-sd-webui-tagcomplete"&gt;DominikDoom/a1111-sd-webui-tagcomplete&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Physton/sd-webui-prompt-all-in-one"&gt;Physton/sd-webui-prompt-all-in-one&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/Bing-su/adetailer"&gt;Bing-su/adetailer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/yankooliveira/sd-webui-photopea-embed"&gt;yankooliveira/sd-webui-photopea-embed&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Stable Diffusion</title><link>https://HoshikawaRyuukou.github.io/posts/illustrious-xl/</link><pubDate>Thu, 06 Feb 2025 10:00:00 +0800</pubDate><guid>https://HoshikawaRyuukou.github.io/posts/illustrious-xl/</guid><description>&lt;h2 id="quick-chat"&gt;Quick Chat&lt;/h2&gt;
&lt;p&gt;目前 Stable Diffusion 只拿來自娛自樂 😃。&lt;/p&gt;
&lt;h2 id="core-working-principles"&gt;Core Working Principles&lt;/h2&gt;
&lt;p&gt;Stable Diffusion 主要包含三個核心技術：&lt;/p&gt;
&lt;h3 id="前向擴散forward-diffusion"&gt;前向擴散（Forward Diffusion）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;先從大量圖片資料集中學習圖片特徵。&lt;/li&gt;
&lt;li&gt;然後，系統會逐步加入高斯雜訊（Gaussian Noise），使圖片變得模糊、無法辨識。&lt;/li&gt;
&lt;li&gt;最後，這個過程會讓圖片變成完全的純雜訊（random noise）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="反向去噪reverse-denoising--u-net"&gt;反向去噪（Reverse Denoising / U-Net）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Stable Diffusion 學習如何逆向去噪，一步步從雜訊還原出清晰的圖片。&lt;/li&gt;
&lt;li&gt;這部分的關鍵是 U-Net 神經網路架構，它可以在多層次的細節中，捕捉圖片的各種特徵。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="文本引導text-conditioning--clip"&gt;文本引導（Text Conditioning / CLIP）&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Stable Diffusion 之所以能生成符合指令的圖片，是因為它使用了CLIP（Contrastive Language-Image Pretraining）。&lt;/li&gt;
&lt;li&gt;CLIP 會將文字轉換成向量表示（latent embeddings），這些向量再指導模型生成符合描述的圖像。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="diagram"&gt;Diagram&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://developer.nvidia.com/blog/improving-diffusion-models-as-an-alternative-to-gans-part-1/"&gt;Improving Diffusion Models as an Alternative To GANs, Part 1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
 &lt;img src="https://developer-blogs.nvidia.com/wp-content/uploads/2022/04/Generation-with-Diffusion-Models.png" alt="123"&gt;

&lt;/p&gt;
&lt;h2 id="extras"&gt;Extras&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.pttweb.cc/bbs/C_Chat/M.1730732828.A.70C"&gt;Re: [問題] AI 風格怎麼了嗎？為什麼容易膩？ - 看板C_Chat - PTT網頁版&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item></channel></rss>